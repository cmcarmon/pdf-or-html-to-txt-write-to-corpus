{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets            ##all imports used in the code\n",
    "import gensim.utils as gensimUtils\n",
    "import nltk \n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import pandas as pd\n",
    "import scipy.spatial.distance as scipyDistance\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.parsing.preprocessing as preprocessing\n",
    "from gensim.models import Phrases\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from nltk.metrics import scores\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from easy_table import EasyTable\n",
    "import sys\n",
    "\n",
    "sys.argv = [\"\"]\n",
    "textCorpus = (datasets.load_files('NEETS-Electronics Corpus+Physics32k', shuffle=False)) #upload text corpus (46k total texts) best so far has been at 46k texts\n",
    "\n",
    "ET=pd.read_csv('ETrespclean2.csv', encoding='latin1') #get data from student responses set\n",
    "df = pd.DataFrame(ET)    #set ET as dataframe\n",
    "dfIdeal = pd.DataFrame({'Gsentences': ET.GA}) #define ideal answers for tokenization (good answers/Gans).\n",
    "dfIdeal['tokenized_sents'] = dfIdeal.apply(lambda row: nltk.word_tokenize(row['Gsentences']), axis=1)\n",
    "dfStudent = pd.DataFrame({'Ssentences': ET.SA}) #define student answers for tokenization.\n",
    "dfStudent['tokenized_sents'] = dfStudent.apply(lambda row: nltk.word_tokenize(row['Ssentences']), axis=1)\n",
    "Gans = dfIdeal['tokenized_sents'] ##renaming the 2 tokenized sent sets for ease.\n",
    "Sans = dfStudent['tokenized_sents']\n",
    "GansDict = (dfIdeal['tokenized_sents'].to_dict)  #dictionary for tokenized sents\n",
    "SansDict = (dfStudent['tokenized_sents'].to_dict)\n",
    "\n",
    "tokenizedSentences = [(gensimUtils.simple_preprocess(i, deacc=True, min_len=2, max_len=18)) for i in textCorpus.data] #tokenize text corpus to build/train models on\n",
    "tokenizedGans = [(gensimUtils.simple_preprocess(i, deacc=True, min_len=1, max_len=14)) for i in ET.GA] #tokenize Gans and Sans for use in w2v, w2vB, and D2V models matching(LSA allows for unkown terms in tokenized strings. these other models do not.)\n",
    "tokenizedSans = [(gensimUtils.simple_preprocess(i, deacc=True, min_len=1, max_len=14)) for i in ET.SA]\n",
    "\n",
    "tokenizedGansclean = []   #this is done for Gans only to remove answer labels in the text (Gans:). labels like E1:, E2:, E3: etc. are removed in preprocesssing\n",
    "for i in range(5166):\n",
    "    hehe = []\n",
    "    for haha in tokenizedGans[i]:\n",
    "        if haha != 'gans':\n",
    "            hehe.append(haha)\n",
    "    tokenizedGansclean.append(hehe)\n",
    "\n",
    "englishStop = set(stopwords.words(\"english\"))\n",
    "\n",
    "frequency = nltk.FreqDist(nltk.flatten(tokenizedSentences)) #frequency distribution\n",
    "\n",
    "processedCorpus = [[i for i in j if frequency[i] > 1 and i not in englishStop] for j in tokenizedSentences] \n",
    "\n",
    "dictionary = corpora.Dictionary(processedCorpus) # building inverse document frequency matrix to be used by the LSA model\n",
    "termdocMatrix = [dictionary.doc2bow(i) for i in processedCorpus]\n",
    "tfidf = models.TfidfModel(termdocMatrix)\n",
    "tfidfMatrix = tfidf[termdocMatrix]\n",
    "lsaPhys = models.LsiModel(tfidfMatrix, id2word=dictionary, num_topics=310) #LSA physics model with 200 topics/dimensions\n",
    "lsaSpacePhys = lsaPhys[tfidfMatrix]\n",
    "lsaPhys.save(\"NEETS-ELECTRONICS+PHYSICS-LSAmodelv1.2-310\")\n",
    "\n",
    "\n",
    "length = len(ET.GA) \n",
    "i = 0\n",
    "LSAlistylist = []\n",
    "while i < length:                                                             ##cosine similarity for ideal answer and student response LSA model\n",
    "    try:\n",
    "        GansBow = dictionary.doc2bow(tokenizedGansclean[i])\n",
    "        SansBow = dictionary.doc2bow(tokenizedSans[i])\n",
    "        GansVector = pd.DataFrame(lsaPhys[GansBow], columns=['dim','val'])\n",
    "        SansVector = pd.DataFrame(lsaPhys[SansBow], columns=['dim','val'])\n",
    "        matchscore = scipyDistance.cosine(SansVector['val'], GansVector['val'])\n",
    "        j = (1 - matchscore)\n",
    "        LSAlistylist.append(j)\n",
    "        i += 1\n",
    "    except (ValueError, ZeroDivisionError):\n",
    "        b = 0\n",
    "        LSAlistylist.append(b) # do nothing!  \n",
    "        i += 1\n",
    "        if RuntimeWarning:                      # these bad boys can survive for miles without water.\n",
    "            pass\n",
    "        for value in LSAlistylist:              # recodes string n/a into float = 0 for missing values in LSA match scores\n",
    "            if value == 'n/a':\n",
    "                LSAistylist.append(value)\n",
    "LSAnum = [i for i in LSAlistylist]      #update entire set of cosine similarity scores for LSA model as a new column in dataframe \n",
    "LSAse = pd.Series(LSAnum) \n",
    "df['LSAp'] = LSAse.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1b4d97915dde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlsaPhys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLsiModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NEETS-ELECTRONICS+PHYSICS-LSAmodelv1.2-500\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mET\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "lsaPhys = models.LsiModel.load(\"NEETS-ELECTRONICS+PHYSICS-LSAmodelv1.2-500\")\n",
    "\n",
    "\n",
    "\n",
    "length = len(ET.GA) \n",
    "i = 0\n",
    "LSAlistylist = []\n",
    "while i < length:                                                             ##cosine similarity for ideal answer and student response LSA model\n",
    "    try:\n",
    "        GansBow = dictionary.doc2bow(tokenizedGansclean[i])\n",
    "        SansBow = dictionary.doc2bow(tokenizedSans[i])\n",
    "        GansVector = pd.DataFrame(lsaPhys[GansBow], columns=['dim','val'])\n",
    "        SansVector = pd.DataFrame(lsaPhys[SansBow], columns=['dim','val'])\n",
    "        matchscore = scipyDistance.cosine(SansVector['val'], GansVector['val'])\n",
    "        j = (1 - matchscore)\n",
    "        LSAlistylist.append(j)\n",
    "        i += 1\n",
    "    except (ValueError, ZeroDivisionError):\n",
    "        b = 0\n",
    "        LSAlistylist.append(b) # do nothing!  \n",
    "        i += 1\n",
    "        if RuntimeWarning:                      # these bad boys can survive for miles without water.\n",
    "            pass\n",
    "        for value in LSAlistylist:              # recodes string n/a into float = 0 for missing values in LSA match scores\n",
    "            if value == 'n/a':\n",
    "                LSAistylist.append(value)\n",
    "LSAnum = [i for i in LSAlistylist]      #update entire set of cosine similarity scores for LSA model as a new column in dataframe \n",
    "LSAse = pd.Series(LSAnum) \n",
    "df['LSAp'] = LSAse.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jthreshv = 6\n",
    "J2threshv = 6\n",
    "LSAthreshv = .889   #Stringent(S) thresholds .58\n",
    "RegExthreshv = .8\n",
    "\n",
    "JthreshIv = 5\n",
    "J2threshIv = 5\n",
    "LSAthreshIv = .669  #Intermediate(I) thresholds .509 = .443f1 or .515\n",
    "RegExthreshvI = .66\n",
    "\n",
    "JthreshLv = 4\n",
    "J2threshLv = 4\n",
    "LSAthreshLv = .533 #Lenient(L) thresholds(.369 and .42,.427,,428=.538) (.366=.357) .29 and .355 is .536 (.35,.535)\n",
    "RegExthreshvL = .5\n",
    "\n",
    "Jthresh = []                        ##the next 8 for loops are about coding match values for human judges and computer models(LSA,w2v,w2vB,D2V)\n",
    "for value in ET.J1: \n",
    "    if value == Jthreshv: \n",
    "        Jthresh.append(1)  \n",
    "    else: \n",
    "        Jthresh.append(0) \n",
    "J2thresh = [] \n",
    "for value in ET.J2: \n",
    "    if value == J2threshv: \n",
    "        J2thresh.append(1)  \n",
    "    else: \n",
    "        J2thresh.append(0)    \n",
    "LSAthresh = [] \n",
    "for value in df['LSAp']: \n",
    "    if value >= LSAthreshv: \n",
    "        LSAthresh.append(1)\n",
    "    else: \n",
    "        LSAthresh.append(0)\n",
    "RegExthresh = [] \n",
    "for value in df['RegEx']: \n",
    "    if value >= RegExthreshv: \n",
    "        RegExthresh.append(1)\n",
    "    else: \n",
    "        RegExthresh.append(0)\n",
    "\n",
    "\n",
    "RegExthreshI= []        \n",
    "JthreshI = []                        ##the next 8 for loops are about coding match values for human judges and computer models in intermediate thresholds.\n",
    "for value in ET.J1: \n",
    "    if value >= JthreshIv: \n",
    "        JthreshI.append(1)  \n",
    "    else: \n",
    "        JthreshI.append(0) \n",
    "J2threshI = [] \n",
    "for value in ET.J2: \n",
    "    if value >= J2threshIv: \n",
    "        J2threshI.append(1)  \n",
    "    else: \n",
    "        J2threshI.append(0)\n",
    "LSAthreshI = [] \n",
    "for value in df['LSAp']: \n",
    "    if value >= LSAthreshIv: \n",
    "        LSAthreshI.append(1)\n",
    "    else: \n",
    "        LSAthreshI.append(0)\n",
    "for value in df['RegEx']: \n",
    "    if value >= RegExthreshvI: \n",
    "        RegExthreshI.append(1)\n",
    "    else: \n",
    "        RegExthreshI.append(0)\n",
    "\n",
    "RegExthreshL = []\n",
    "JthreshL = []                        ##the next 8 for loops are about coding match values for human judges and computer models in lenient thresholds.\n",
    "for value in ET.J1: \n",
    "    if value >= JthreshLv: \n",
    "        JthreshL.append(1)  \n",
    "    else: \n",
    "        JthreshL.append(0) \n",
    "J2threshL = [] \n",
    "for value in ET.J2: \n",
    "    if value >= J2threshLv: \n",
    "        J2threshL.append(1)  \n",
    "    else: \n",
    "        J2threshL.append(0)     \n",
    "LSAthreshL = [] \n",
    "for value in df['LSAp']: \n",
    "    if value >= LSAthreshLv: \n",
    "        LSAthreshL.append(1)\n",
    "    else: \n",
    "        LSAthreshL.append(0)  \n",
    "for value in df['RegEx']: \n",
    "    if value >= RegExthreshvL: \n",
    "        RegExthreshL.append(1)\n",
    "    else: \n",
    "        RegExthreshL.append(0)\n",
    "        \n",
    "LSAcm = confusion_matrix(Jthresh, LSAthresh)  #confusion matrix to plug into precision and recall tool\n",
    "LSAcm2 = confusion_matrix(J2thresh, LSAthresh)  #confusion matrix to plug into precision and recall tool\n",
    "LSAcmJ = confusion_matrix(Jthresh, J2thresh)\n",
    "\n",
    "LSAcmI = confusion_matrix(JthreshI, LSAthreshI)  #confusion matrix to plug into precision and recall tool\n",
    "LSAcmI2 = confusion_matrix(J2threshI, LSAthreshI)  #confusion matrix to plug into precision and recall tool\n",
    "LSAcmJI = confusion_matrix(JthreshI, J2threshI) \n",
    "\n",
    "LSAcmL = confusion_matrix(JthreshL, LSAthreshL)  #confusion matrix to plug into precision and recall tool\n",
    "LSAcmL2 = confusion_matrix(J2threshL, LSAthreshL)  #confusion matrix to plug into precision and recall tool\n",
    "LSAcmJL = confusion_matrix(JthreshL, J2threshL)\n",
    "\n",
    "LSAcmSI = confusion_matrix(Jthresh, J2threshI)\n",
    "LSAcmSL = confusion_matrix(Jthresh, J2threshL)\n",
    "LSAcmIS = confusion_matrix(JthreshI, J2thresh)\n",
    "LSAcmIL = confusion_matrix(JthreshI, J2threshL)\n",
    "LSAcmLS = confusion_matrix(JthreshL, J2thresh)\n",
    "LSAcmLI = confusion_matrix(JthreshL, J2threshI) #Judges\n",
    "\n",
    "LSAcmSI1 = confusion_matrix(Jthresh, LSAthreshI)\n",
    "LSAcmSL1 = confusion_matrix(Jthresh, LSAthreshL)\n",
    "LSAcmIS1 = confusion_matrix(JthreshI, LSAthresh)\n",
    "LSAcmIL1 = confusion_matrix(JthreshI, LSAthreshL)\n",
    "LSAcmLS1 = confusion_matrix(JthreshL, LSAthresh)\n",
    "LSAcmLI1 = confusion_matrix(JthreshL, LSAthreshI) #J1/LSA\n",
    "\n",
    "LSAcmSI2 = confusion_matrix(J2thresh, LSAthreshI)\n",
    "LSAcmSL2 = confusion_matrix(J2thresh, LSAthreshL)\n",
    "LSAcmIS2 = confusion_matrix(J2threshI, LSAthresh)\n",
    "LSAcmIL2 = confusion_matrix(J2threshI, LSAthreshL)\n",
    "LSAcmLS2 = confusion_matrix(J2threshL, LSAthresh)\n",
    "LSAcmLI2 = confusion_matrix(J2threshL, LSAthreshI) #J2/LSA add f1\n",
    "\n",
    "tpSI1 = LSAcmSI1[1,1]\n",
    "tnSI1 = LSAcmSI1[0,0]\n",
    "pSI1 = (LSAcmSI1[1,0] + LSAcmSI1[1,1])                    ##LSA vs Judge 1\n",
    "nSI1 = (LSAcmSI1[0,0] + LSAcmSI1[0,1])\n",
    "fpSI1 = LSAcmSI1[1,0]\n",
    "fnSI1 = LSAcmSI1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracySI = (tpSI1 + tnSI1) / (pSI1 + nSI1)\n",
    "# precision tp / (tp + fp)\n",
    "precisionSI = tpSI1 / (tpSI1 + fpSI1)\n",
    "# recall: tp / (tp + fn)\n",
    "recallSI = tpSI1 / (tpSI1 + fnSI1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1SI1 = 2*tpSI1 / (2*tpSI1 + fpSI1 + fnSI1)\n",
    "\n",
    "tpSL1 = LSAcmSL1[1,1]\n",
    "tnSL1 = LSAcmSL1[0,0]\n",
    "pSL1 = (LSAcmSL1[1,0] + LSAcmSL1[1,1])                    ##LSA vs Judge 1\n",
    "nSL1 = (LSAcmSL1[0,0] + LSAcmSL1[0,1])\n",
    "fpSL1 = LSAcmSL1[1,0]\n",
    "fnSL1 = LSAcmSL1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracySL = (tpSL1 + tnSL1) / (pSL1 + nSL1)\n",
    "# precision tp / (tp + fp)\n",
    "precisionSL = tpSL1 / (tpSL1 + fpSL1)\n",
    "# recall: tp / (tp + fn)\n",
    "recallSL = tpSL1 / (tpSL1 + fnSL1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1SL1 = 2*tpSL1 / (2*tpSL1 + fpSL1 + fnSL1)\n",
    "\n",
    "tpIS1 = LSAcmIS1[1,1]\n",
    "tnIS1 = LSAcmIS1[0,0]\n",
    "pIS1 = (LSAcmIS1[1,0] + LSAcmIS1[1,1])                    ##LSA vs Judge 1\n",
    "nIS1 = (LSAcmIS1[0,0] + LSAcmIS1[0,1])\n",
    "fpIS1 = LSAcmIS1[1,0]\n",
    "fnIS1 = LSAcmIS1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyIS = (tpIS1 + tnIS1) / (pIS1 + nIS1)\n",
    "# precision tp / (tp + fp)\n",
    "precisionIS = tpIS1 / (tpIS1 + fpIS1)\n",
    "# recall: tp / (tp + fn)\n",
    "recallIS = tpIS1 / (tpIS1 + fnIS1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1IS1 = 2*tpIS1 / (2*tpIS1 + fpIS1 + fnIS1)\n",
    "\n",
    "tpIL1 = LSAcmIL1[1,1]\n",
    "tnIL1 = LSAcmIL1[0,0]\n",
    "pIL1 = (LSAcmIL1[1,0] + LSAcmIL1[1,1])                    ##LSA vs Judge 1\n",
    "nIL1 = (LSAcmIL1[0,0] + LSAcmIL1[0,1])\n",
    "fpIL1 = LSAcmIL1[1,0]\n",
    "fnIL1 = LSAcmIL1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyIL = (tpIL1 + tnIL1) / (pIL1 + nIL1)\n",
    "# precision tp / (tp + fp)\n",
    "precisionIL = tpIL1 / (tpIL1 + fpIL1)\n",
    "# recall: tp / (tp + fn)\n",
    "recallIL = tpIL1 / (tpIL1 + fnIL1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1IL1 = 2*tpIL1 / (2*tpIL1 + fpIL1 + fnIL1)\n",
    "\n",
    "tpLS1 = LSAcmLS1[1,1]\n",
    "tnLS1 = LSAcmLS1[0,0]\n",
    "pLS1 = (LSAcmLS1[1,0] + LSAcmLS1[1,1])                    ##LSA vs Judge 1\n",
    "nLS1 = (LSAcmLS1[0,0] + LSAcmLS1[0,1])\n",
    "fpLS1 = LSAcmLS1[1,0]\n",
    "fnLS1 = LSAcmLS1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyLS = (tpLS1 + tnLS1) / (pLS1 + nLS1)\n",
    "# precision tp / (tp + fp)\n",
    "precisionLS = tpLS1 / (tpLS1 + fpLS1)\n",
    "# recall: tp / (tp + fn)\n",
    "recallLS = tpLS1 / (tpLS1 + fnLS1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1LS1 = 2*tpLS1 / (2*tpLS1 + fpLS1 + fnLS1)\n",
    "\n",
    "tpLI1 = LSAcmLI1[1,1]\n",
    "tnLI1 = LSAcmLI1[0,0]\n",
    "pLI1 = (LSAcmLI1[1,0] + LSAcmLI1[1,1])                    ##LSA vs Judge 1\n",
    "nLI1 = (LSAcmLI1[0,0] + LSAcmLI1[0,1])\n",
    "fpLI1 = LSAcmLI1[1,0]\n",
    "fnLI1 = LSAcmLI1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyLI = (tpLI1 + tnLI1) / (pLI1 + nLI1)\n",
    "# precision tp / (tp + fp)\n",
    "precisionLI = tpLI1 / (tpLI1 + fpLI1)\n",
    "# recall: tp / (tp + fn)\n",
    "recallLI = tpLI1 / (tpLI1 + fnLI1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1LI1 = 2*tpLI1 / (2*tpLI1 + fpLI1 + fnLI1)\n",
    "\n",
    "##stop\n",
    "\n",
    "tpSI = LSAcmSI[1,1]\n",
    "tnSI = LSAcmSI[0,0]\n",
    "pSI = (LSAcmSI[1,0] + LSAcmSI[1,1])                    ##LSA vs Judge 1\n",
    "nSI = (LSAcmSI[0,0] + LSAcmSI[0,1])\n",
    "fpSI = LSAcmSI[1,0]\n",
    "fnSI = LSAcmSI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracySI = (tpSI + tnSI) / (pSI + nSI)\n",
    "# precision tp / (tp + fp)\n",
    "precisionSI = tpSI / (tpSI + fpSI)\n",
    "# recall: tp / (tp + fn)\n",
    "recallSI = tpSI / (tpSI + fnSI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1SI = 2*tpSI / (2*tpSI + fpSI + fnSI)\n",
    "\n",
    "tpSL = LSAcmSL[1,1]\n",
    "tnSL = LSAcmSL[0,0]\n",
    "pSL = (LSAcmSL[1,0] + LSAcmSL[1,1])                    ##LSA vs Judge 1\n",
    "nSL = (LSAcmSL[0,0] + LSAcmSL[0,1])\n",
    "fpSL = LSAcmSL[1,0]\n",
    "fnSL = LSAcmSL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracySL = (tpSL + tnSL) / (pSL + nSL)\n",
    "# precision tp / (tp + fp)\n",
    "precisionSL = tpSL / (tpSL + fpSL)\n",
    "# recall: tp / (tp + fn)\n",
    "recallSL = tpSL / (tpSL + fnSL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1SL = 2*tpSL / (2*tpSL + fpSL + fnSL)\n",
    "\n",
    "tpIS = LSAcmIS[1,1]\n",
    "tnIS = LSAcmIS[0,0]\n",
    "pIS = (LSAcmIS[1,0] + LSAcmIS[1,1])                    ##LSA vs Judge 1\n",
    "nIS = (LSAcmIS[0,0] + LSAcmIS[0,1])\n",
    "fpIS = LSAcmIS[1,0]\n",
    "fnIS = LSAcmIS[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyIS = (tpIS + tnIS) / (pIS + nIS)\n",
    "# precision tp / (tp + fp)\n",
    "precisionIS = tpIS / (tpIS + fpIS)\n",
    "# recall: tp / (tp + fn)\n",
    "recallIS = tpIS / (tpIS + fnIS)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1IS = 2*tpIS / (2*tpIS + fpIS + fnIS)\n",
    "\n",
    "tpIL = LSAcmIL[1,1]\n",
    "tnIL = LSAcmIL[0,0]\n",
    "pIL = (LSAcmIL[1,0] + LSAcm[1,1])                    ##LSA vs Judge 1\n",
    "nIL = (LSAcmIL[0,0] + LSAcm[0,1])\n",
    "fpIL = LSAcmIL[1,0]\n",
    "fnIL = LSAcmIL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyIL = (tpIL + tnIL) / (pIL + nIL)\n",
    "# precision tp / (tp + fp)\n",
    "precisionIL = tpIL / (tpIL + fpIL)\n",
    "# recall: tp / (tp + fn)\n",
    "recallIL = tpIL / (tpIL + fnIL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1IL = 2*tpIL / (2*tpIL + fpIL + fnIL)\n",
    "\n",
    "tpLS = LSAcmLS[1,1]\n",
    "tnLS = LSAcmLS[0,0]\n",
    "pLS = (LSAcmLS[1,0] + LSAcmLS[1,1])                    ##LSA vs Judge 1\n",
    "nLS = (LSAcmLS[0,0] + LSAcmLS[0,1])\n",
    "fpLS = LSAcmLS[1,0]\n",
    "fnLS = LSAcmLS[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyLS = (tpLS + tnLS) / (pLS + nLS)\n",
    "# precision tp / (tp + fp)\n",
    "precisionLS = tpLS / (tpLS + fpLS)\n",
    "# recall: tp / (tp + fn)\n",
    "recallLS = tpLS / (tpLS + fnLS)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1LS = 2*tpLS / (2*tpLS + fpLS + fnLS)\n",
    "\n",
    "tpLI = LSAcmLI[1,1]\n",
    "tnLI = LSAcmLI[0,0]\n",
    "pLI = (LSAcmLI[1,0] + LSAcmLI[1,1])                    ##LSA vs Judge 1\n",
    "nLI = (LSAcmLI[0,0] + LSAcmLI[0,1])\n",
    "fpLI = LSAcmLI[1,0]\n",
    "fnLI = LSAcmLI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyLI = (tpLI + tnLI) / (pLI + nLI)\n",
    "# precision tp / (tp + fp)\n",
    "precisionLI = tpLI / (tpLI + fpLI)\n",
    "# recall: tp / (tp + fn)\n",
    "recallLI = tpLI / (tpLI + fnLI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1LI = 2*tpLI / (2*tpLI + fpLI + fnLI)\n",
    "\n",
    "tp = LSAcm[1,1]\n",
    "tn = LSAcm[0,0]\n",
    "p = (LSAcm[1,0] + LSAcm[1,1])                    ##LSA vs Judge 1\n",
    "n = (LSAcm[0,0] + LSAcm[0,1])\n",
    "fp = LSAcm[1,0]\n",
    "fn = LSAcm[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = (tp + tn) / (p + n)\n",
    "# precision tp / (tp + fp)\n",
    "precision = tp / (tp + fp)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = tp / (tp + fn)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = 2*tp / (2*tp + fp + fn)\n",
    "\n",
    "tpJ = LSAcmJ[1,1]\n",
    "tnJ = LSAcmJ[0,0]\n",
    "pJ = (LSAcmJ[1,0] + LSAcmJ[1,1])                    ##Judge vs Judge 2 stringent\n",
    "nJ = (LSAcmJ[0,0] + LSAcmJ[0,1])\n",
    "fpJ = LSAcmJ[1,0]\n",
    "fnJ = LSAcmJ[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyJ = (tpJ + tnJ) / (pJ + nJ)\n",
    "# precision tp / (tp + fp)\n",
    "precisionJ = tpJ / (tpJ + fpJ)\n",
    "# recall: tp / (tp + fn)\n",
    "\n",
    "recallJ = tpJ / (tpJ + fnJ)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1J = 2*tpJ / (2*tpJ + fpJ + fnJ)\n",
    "\n",
    "tp = LSAcm[1,1]\n",
    "tn = LSAcm[0,0]\n",
    "p = (LSAcm[1,0] + LSAcm[1,1])                    ##LSA vs Judge 1\n",
    "n = (LSAcm[0,0] + LSAcm[0,1])\n",
    "fp = LSAcm[1,0]\n",
    "fn = LSAcm[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = (tp + tn) / (p + n)\n",
    "# precision tp / (tp + fp)\n",
    "precision = tp / (tp + fp)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = tp / (tp + fn)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = 2*tp / (2*tp + fp + fn)\n",
    "\n",
    "tp2 = LSAcm2[1,1]\n",
    "tn2 = LSAcm2[0,0]\n",
    "p2 = (LSAcm2[1,0] + LSAcm2[1,1])                    ##LSA vs Judge 2\n",
    "n2 = (LSAcm2[0,0] + LSAcm2[0,1])\n",
    "fp2 = LSAcm2[1,0]\n",
    "fn2 = LSAcm2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy2 = (tp2 + tn2) / (p2 + n2)\n",
    "# precision tp / (tp + fp)\n",
    "precision2 = tp2 / (tp2 + fp2)\n",
    "# recall: tp / (tp + fn)\n",
    "recall2 = tp2 / (tp2 + fn2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f12 = 2*tp2 / (2*tp2 + fp2 + fn2)\n",
    "\n",
    "\n",
    "tpJI = LSAcmJI[1,1]\n",
    "tnJI = LSAcmJI[0,0]\n",
    "pJI = (LSAcmJI[1,0] + LSAcmJI[1,1])\n",
    "nJI = (LSAcmJI[0,0] + LSAcmJI[0,1])\n",
    "fpJI = LSAcmJI[1,0]\n",
    "fnJI = LSAcmJI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyJI = (tpJI + tnJI) / (pJI + nJI)\n",
    "# precision tp / (tp + fp)\n",
    "precisionJI = tpJI / (tpJI + fpJI)\n",
    "# recall: tp / (tp + fn)\n",
    "recallJI = tpJI / (tpJI + fnJI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1JI = 2*tpJI / (2*tpJI + fpJI + fnJI)\n",
    "\n",
    "tpI = LSAcmI[1,1]\n",
    "tnI = LSAcmI[0,0]\n",
    "pI = (LSAcmI[1,0] + LSAcmI[1,1])\n",
    "nI = (LSAcmI[0,0] + LSAcmI[0,1])\n",
    "fpI = LSAcmI[1,0]\n",
    "fnI = LSAcmI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyI = (tpI + tnI) / (pI + nI)\n",
    "# precision tp / (tp + fp)\n",
    "precisionI = tpI / (tpI + fpI)\n",
    "# recall: tp / (tp + fn)\n",
    "recallI = tpI / (tpI + fnI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1I = 2*tpI / (2*tpI + fpI + fnI)\n",
    "\n",
    "tpI2 = LSAcmI2[1,1]\n",
    "tnI2 = LSAcmI2[0,0]\n",
    "pI2 = (LSAcmI2[1,0] + LSAcmI2[1,1])\n",
    "nI2 = (LSAcmI2[0,0] + LSAcmI2[0,1])\n",
    "fpI2 = LSAcmI2[1,0]\n",
    "fnI2 = LSAcmI2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyI2 = (tpI2 + tnI2) / (pI2 + nI2)\n",
    "# precision tp / (tp + fp)\n",
    "precisionI2 = tpI2 / (tpI2 + fpI2)\n",
    "# recall: tp / (tp + fn)\n",
    "recallI2 = tpI2 / (tpI2 + fnI2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1I2 = 2*tpI2 / (2*tpI2 + fpI2 + fnI2)\n",
    "\n",
    "\n",
    "tpJL = LSAcmJL[1,1]\n",
    "tnJL = LSAcmJL[0,0]\n",
    "pJL = (LSAcmJL[1,0] + LSAcmJL[1,1])\n",
    "nJL = (LSAcmJL[0,0] + LSAcmJL[0,1])\n",
    "fpJL = LSAcmJL[1,0]\n",
    "fnJL = LSAcmJL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyJL = (tpJL + tnJL) / (pJL + nJL)\n",
    "# precision tp / (tp + fp)\n",
    "precisionJL = tpJL / (tpJL + fpJL)\n",
    "recallJL = tpJL / (tpJL + fnJL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1JL = 2*tpJL / (2*tpJL + fpJL + fnJL)\n",
    "\n",
    "tpL = LSAcmL[1,1]\n",
    "tnL = LSAcmL[0,0]\n",
    "pL = (LSAcmL[1,0] + LSAcmL[1,1])\n",
    "nL = (LSAcmL[0,0] + LSAcmL[0,1])\n",
    "fpL = LSAcmL[1,0]\n",
    "fnL = LSAcmL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyL = (tpL + tnL) / (pL + nL)\n",
    "# precision tp / (tp + fp)\n",
    "precisionL = tpL / (tpL + fpL)\n",
    "recallL = tpL / (tpL + fnL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1L = 2*tpL / (2*tpL + fpL + fnL)\n",
    "\n",
    "tpL2 = LSAcmL2[1,1]\n",
    "tnL2 = LSAcmL2[0,0]\n",
    "pL2 = (LSAcmL2[1,0] + LSAcmL2[1,1])\n",
    "nL2 = (LSAcmL2[0,0] + LSAcmL2[0,1])\n",
    "fpL2 = LSAcmL2[1,0]\n",
    "fnL2 = LSAcmL2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracyL2 = (tpL2 + tnL2) / (pL2 + nL2)\n",
    "# precision tp / (tp + fp)\n",
    "precisionL2 = tpL2 / (tpL2 + fpL2)\n",
    "recallL2 = tpL2 / (tpL2 + fnL2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1L2 = 2*tpL2 / (2*tpL2 + fpL2 + fnL2)\n",
    "\n",
    "RegExcm = confusion_matrix(Jthresh, RegExthresh)  #confusion matrix to plug into precision and recall tool\n",
    "RegExcm2 = confusion_matrix(J2thresh, RegExthresh)  #confusion matrix to plug into precision and recall tool\n",
    "RegExcmJ = confusion_matrix(Jthresh, J2thresh)\n",
    "\n",
    "RegExcmI = confusion_matrix(JthreshI, RegExthreshI)  #confusion matrix to plug into precision and recall tool\n",
    "RegExcmI2 = confusion_matrix(J2threshI, RegExthreshI)  #confusion matrix to plug into precision and recall tool\n",
    "RegExcmJI = confusion_matrix(JthreshI, J2threshI) \n",
    "\n",
    "RegExcmL = confusion_matrix(JthreshL, RegExthreshL)  #confusion matrix to plug into precision and recall tool\n",
    "RegExcmL2 = confusion_matrix(J2threshL, RegExthreshL)  #confusion matrix to plug into precision and recall tool\n",
    "RegExcmJL = confusion_matrix(JthreshL, J2threshL)\n",
    "\n",
    "RegExcmSI = confusion_matrix(Jthresh, J2threshI)\n",
    "RegExcmSL = confusion_matrix(Jthresh, J2threshL)\n",
    "RegExcmIS = confusion_matrix(JthreshI, J2thresh)\n",
    "RegExcmIL = confusion_matrix(JthreshI, J2threshL)\n",
    "RegExcmLS = confusion_matrix(JthreshL, J2thresh)\n",
    "RegExcmLI = confusion_matrix(JthreshL, J2threshI) #Judges\n",
    "\n",
    "RegExcmSI1 = confusion_matrix(Jthresh, RegExthreshI)\n",
    "RegExcmSL1 = confusion_matrix(Jthresh, RegExthreshL)\n",
    "RegExcmIS1 = confusion_matrix(JthreshI, RegExthresh)\n",
    "RegExcmIL1 = confusion_matrix(JthreshI, RegExthreshL)\n",
    "RegExcmLS1 = confusion_matrix(JthreshL, RegExthresh)\n",
    "RegExcmLI1 = confusion_matrix(JthreshL, RegExthreshI) #J1/RegEx\n",
    "\n",
    "RegExcmSI2 = confusion_matrix(J2thresh, RegExthreshI)\n",
    "RegExcmSL2 = confusion_matrix(J2thresh, RegExthreshL)\n",
    "RegExcmIS2 = confusion_matrix(J2threshI, RegExthresh)\n",
    "RegExcmIL2 = confusion_matrix(J2threshI, RegExthreshL)\n",
    "RegExcmLS2 = confusion_matrix(J2threshL, RegExthresh)\n",
    "RegExcmLI2 = confusion_matrix(J2threshL, RegExthreshI) #J2/RegEx add f1\n",
    "\n",
    "REtpSI1 = RegExcmSI1[1,1]\n",
    "REtnSI1 = RegExcmSI1[0,0]\n",
    "REpSI1 = (RegExcmSI1[1,0] + RegExcmSI1[1,1])                    ##RegEx vs Judge 1\n",
    "REnSI1 = (RegExcmSI1[0,0] + RegExcmSI1[0,1])\n",
    "REfpSI1 = RegExcmSI1[1,0]\n",
    "REfnSI1 = RegExcmSI1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracySI = (REtpSI1 + REtnSI1) / (REpSI1 + REnSI1)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionSI = REtpSI1 / (REtpSI1 + REfpSI1)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallSI = REtpSI1 / (REtpSI1 + REfnSI1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1SI1 = 2*REtpSI1 / (2*REtpSI1 + REfpSI1 + REfnSI1)\n",
    "\n",
    "REtpSL1 = RegExcmSL1[1,1]\n",
    "REtnSL1 = RegExcmSL1[0,0]\n",
    "REpSL1 = (RegExcmSL1[1,0] + RegExcmSL1[1,1])                    ##RegEx vs Judge 1\n",
    "REnSL1 = (RegExcmSL1[0,0] + RegExcmSL1[0,1])\n",
    "REfpSL1 = RegExcmSL1[1,0]\n",
    "REfnSL1 = RegExcmSL1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracySL = (REtpSL1 + REtnSL1) / (REpSL1 + REnSL1)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionSL = REtpSL1 / (REtpSL1 + REfpSL1)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallSL = REtpSL1 / (REtpSL1 + REfnSL1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1SL1 = 2*REtpSL1 / (2*REtpSL1 + REfpSL1 + REfnSL1)\n",
    "\n",
    "REtpIS1 = RegExcmIS1[1,1]\n",
    "REtnIS1 = RegExcmIS1[0,0]\n",
    "REpIS1 = (RegExcmIS1[1,0] + RegExcmIS1[1,1])                    ##RegEx vs Judge 1\n",
    "REnIS1 = (RegExcmIS1[0,0] + RegExcmIS1[0,1])\n",
    "REfpIS1 = RegExcmIS1[1,0]\n",
    "REfnIS1 = RegExcmIS1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyIS = (REtpIS1 + REtnIS1) / (REpIS1 + REnIS1)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionIS = REtpIS1 / (REtpIS1 + REfpIS1)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallIS = REtpIS1 / (REtpIS1 + REfnIS1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1IS1 = 2*REtpIS1 / (2*REtpIS1 + REfpIS1 + REfnIS1)\n",
    "\n",
    "REtpIL1 = RegExcmIL1[1,1]\n",
    "REtnIL1 = RegExcmIL1[0,0]\n",
    "REpIL1 = (RegExcmIL1[1,0] + RegExcmIL1[1,1])                    ##RegEx vs Judge 1\n",
    "REnIL1 = (RegExcmIL1[0,0] + RegExcmIL1[0,1])\n",
    "REfpIL1 = RegExcmIL1[1,0]\n",
    "REfnIL1 = RegExcmIL1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyIL = (REtpIL1 + REtnIL1) / (REpIL1 + REnIL1)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionIL = REtpIL1 / (REtpIL1 + REfpIL1)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallIL = REtpIL1 / (REtpIL1 + REfnIL1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1IL1 = 2*REtpIL1 / (2*REtpIL1 + REfpIL1 + REfnIL1)\n",
    "\n",
    "REtpLS1 = RegExcmLS1[1,1]\n",
    "REtnLS1 = RegExcmLS1[0,0]\n",
    "REpLS1 = (RegExcmLS1[1,0] + RegExcmLS1[1,1])                    ##RegEx vs Judge 1\n",
    "REnLS1 = (RegExcmLS1[0,0] + RegExcmLS1[0,1])\n",
    "REfpLS1 = RegExcmLS1[1,0]\n",
    "REfnLS1 = RegExcmLS1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyLS = (REtpLS1 + REtnLS1) / (REpLS1 + REnLS1)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionLS = REtpLS1 / (REtpLS1 + REfpLS1)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallLS = REtpLS1 / (REtpLS1 + REfnLS1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1LS1 = 2*REtpLS1 / (2*REtpLS1 + REfpLS1 + REfnLS1)\n",
    "\n",
    "REtpLI1 = RegExcmLI1[1,1]\n",
    "REtnLI1 = RegExcmLI1[0,0]\n",
    "REpLI1 = (RegExcmLI1[1,0] + RegExcmLI1[1,1])                    ##RegEx vs Judge 1\n",
    "REnLI1 = (RegExcmLI1[0,0] + RegExcmLI1[0,1])\n",
    "REfpLI1 = RegExcmLI1[1,0]\n",
    "REfnLI1 = RegExcmLI1[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyLI = (REtpLI1 + REtnLI1) / (REpLI1 + REnLI1)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionLI = REtpLI1 / (REtpLI1 + REfpLI1)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallLI = REtpLI1 / (REtpLI1 + REfnLI1)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1LI1 = 2*REtpLI1 / (2*REtpLI1 + REfpLI1 + REfnLI1)\n",
    "\n",
    "##stop\n",
    "\n",
    "REtpSI = RegExcmSI[1,1]\n",
    "REtnSI = RegExcmSI[0,0]\n",
    "REpSI = (RegExcmSI[1,0] + RegExcmSI[1,1])                    ##RegEx vs Judge 1\n",
    "REnSI = (RegExcmSI[0,0] + RegExcmSI[0,1])\n",
    "REfpSI = RegExcmSI[1,0]\n",
    "REfnSI = RegExcmSI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracySI = (REtpSI + REtnSI) / (REpSI + REnSI)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionSI = REtpSI / (REtpSI + REfpSI)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallSI = REtpSI / (REtpSI + REfnSI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1SI = 2*REtpSI / (2*REtpSI + REfpSI + REfnSI)\n",
    "\n",
    "REtpSL = RegExcmSL[1,1]\n",
    "REtnSL = RegExcmSL[0,0]\n",
    "REpSL = (RegExcmSL[1,0] + RegExcmSL[1,1])                    ##RegEx vs Judge 1\n",
    "REnSL = (RegExcmSL[0,0] + RegExcmSL[0,1])\n",
    "REfpSL = RegExcmSL[1,0]\n",
    "REfnSL = RegExcmSL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracySL = (REtpSL + REtnSL) / (REpSL + REnSL)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionSL = REtpSL / (REtpSL + REfpSL)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallSL = REtpSL / (REtpSL + REfnSL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1SL = 2*REtpSL / (2*REtpSL + REfpSL + REfnSL)\n",
    "\n",
    "REtpIS = RegExcmIS[1,1]\n",
    "REtnIS = RegExcmIS[0,0]\n",
    "REpIS = (RegExcmIS[1,0] + RegExcmIS[1,1])                    ##RegEx vs Judge 1\n",
    "REnIS = (RegExcmIS[0,0] + RegExcmIS[0,1])\n",
    "REfpIS = RegExcmIS[1,0]\n",
    "REfnIS = RegExcmIS[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyIS = (REtpIS + REtnIS) / (REpIS + REnIS)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionIS = REtpIS / (REtpIS + REfpIS)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallIS = REtpIS / (REtpIS + REfnIS)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1IS = 2*REtpIS / (2*REtpIS + REfpIS + REfnIS)\n",
    "\n",
    "REtpIL = RegExcmIL[1,1]\n",
    "REtnIL = RegExcmIL[0,0]\n",
    "REpIL = (RegExcmIL[1,0] + RegExcm[1,1])                    ##RegEx vs Judge 1\n",
    "REnIL = (RegExcmIL[0,0] + RegExcm[0,1])\n",
    "REfpIL = RegExcmIL[1,0]\n",
    "REfnIL = RegExcmIL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyIL = (REtpIL + REtnIL) / (REpIL + REnIL)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionIL = REtpIL / (REtpIL + REfpIL)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallIL = REtpIL / (REtpIL + REfnIL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1IL = 2*REtpIL / (2*REtpIL + REfpIL + REfnIL)\n",
    "\n",
    "REtpLS = RegExcmLS[1,1]\n",
    "REtnLS = RegExcmLS[0,0]\n",
    "REpLS = (RegExcmLS[1,0] + RegExcmLS[1,1])                    ##RegEx vs Judge 1\n",
    "REnLS = (RegExcmLS[0,0] + RegExcmLS[0,1])\n",
    "REfpLS = RegExcmLS[1,0]\n",
    "REfnLS = RegExcmLS[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyLS = (REtpLS + REtnLS) / (REpLS + REnLS)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionLS = REtpLS / (REtpLS + REfpLS)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallLS = REtpLS / (REtpLS + REfnLS)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1LS = 2*REtpLS / (2*REtpLS + REfpLS + REfnLS)\n",
    "\n",
    "REtpLI = RegExcmLI[1,1]\n",
    "REtnLI = RegExcmLI[0,0]\n",
    "REpLI = (RegExcmLI[1,0] + RegExcmLI[1,1])                    ##RegEx vs Judge 1\n",
    "REnLI = (RegExcmLI[0,0] + RegExcmLI[0,1])\n",
    "REfpLI = RegExcmLI[1,0]\n",
    "REfnLI = RegExcmLI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyLI = (REtpLI + REtnLI) / (REpLI + REnLI)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionLI = REtpLI / (REtpLI + REfpLI)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallLI = REtpLI / (REtpLI + REfnLI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1LI = 2*REtpLI / (2*REtpLI + REfpLI + REfnLI)\n",
    "\n",
    "REtp = RegExcm[1,1]\n",
    "REtn = RegExcm[0,0]\n",
    "REp = (RegExcm[1,0] + RegExcm[1,1])                    ##RegEx vs Judge 1\n",
    "REn = (RegExcm[0,0] + RegExcm[0,1])\n",
    "REfp = RegExcm[1,0]\n",
    "REfn = RegExcm[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracy = (REtp + REtn) / (REp + REn)\n",
    "# precision tp / (tp + fp)\n",
    "REprecision = REtp / (REtp + REfp)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecall = REtp / (REtp + REfn)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1 = 2*REtp / (2*REtp + REfp + REfn)\n",
    "\n",
    "REtpJ = RegExcmJ[1,1]\n",
    "REtnJ = RegExcmJ[0,0]\n",
    "REpJ = (RegExcmJ[1,0] + RegExcmJ[1,1])                    ##Judge vs Judge 2 stringent\n",
    "REnJ = (RegExcmJ[0,0] + RegExcmJ[0,1])\n",
    "REfpJ = RegExcmJ[1,0]\n",
    "REfnJ = RegExcmJ[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyJ = (REtpJ + REtnJ) / (REpJ + REnJ)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionJ = REtpJ / (REtpJ + REfpJ)\n",
    "# recall: tp / (tp + fn)\n",
    "\n",
    "RErecallJ = REtpJ / (REtpJ + REfnJ)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1J = 2*REtpJ / (2*REtpJ + REfpJ + REfnJ)\n",
    "\n",
    "REtp = RegExcm[1,1]\n",
    "REtn = RegExcm[0,0]\n",
    "REp = (RegExcm[1,0] + RegExcm[1,1])                    ##RegEx vs Judge 1\n",
    "REn = (RegExcm[0,0] + RegExcm[0,1])\n",
    "REfp = RegExcm[1,0]\n",
    "REfn = RegExcm[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracy = (REtp + REtn) / (REp + REn)\n",
    "# precision tp / (tp + fp)\n",
    "REprecision = REtp / (REtp + REfp)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecall = REtp / (REtp + REfn)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1 = 2*REtp / (2*REtp + REfp + REfn)\n",
    "\n",
    "REtp2 = RegExcm2[1,1]\n",
    "REtn2 = RegExcm2[0,0]\n",
    "REp2 = (RegExcm2[1,0] + RegExcm2[1,1])                    ##RegEx vs Judge 2\n",
    "REn2 = (RegExcm2[0,0] + RegExcm2[0,1])\n",
    "REfp2 = RegExcm2[1,0]\n",
    "REfn2 = RegExcm2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracy2 = (REtp2 + REtn2) / (REp2 + REn2)\n",
    "# precision tp / (tp + fp)\n",
    "REprecision2 = REtp2 / (REtp2 + REfp2)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecall2 = REtp2 / (REtp2 + REfn2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf12 = 2*REtp2 / (2*REtp2 + REfp2 + REfn2)\n",
    "\n",
    "\n",
    "REtpJI = RegExcmJI[1,1]\n",
    "REtnJI = RegExcmJI[0,0]\n",
    "REpJI = (RegExcmJI[1,0] + RegExcmJI[1,1])\n",
    "REnJI = (RegExcmJI[0,0] + RegExcmJI[0,1])\n",
    "REfpJI = RegExcmJI[1,0]\n",
    "REfnJI = RegExcmJI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyJI = (REtpJI + REtnJI) / (REpJI + REnJI)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionJI = REtpJI / (REtpJI + REfpJI)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallJI = REtpJI / (REtpJI + REfnJI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1JI = 2*REtpJI / (2*REtpJI + REfpJI + REfnJI)\n",
    "\n",
    "REtpI = RegExcmI[1,1]\n",
    "REtnI = RegExcmI[0,0]\n",
    "REpI = (RegExcmI[1,0] + RegExcmI[1,1])\n",
    "REnI = (RegExcmI[0,0] + RegExcmI[0,1])\n",
    "REfpI = RegExcmI[1,0]\n",
    "REfnI = RegExcmI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyI = (REtpI + REtnI) / (REpI + REnI)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionI = REtpI / (REtpI + REfpI)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallI = REtpI / (REtpI + REfnI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1I = 2*REtpI / (2*REtpI + REfpI + REfnI)\n",
    "\n",
    "REtpI2 = RegExcmI2[1,1]\n",
    "REtnI2 = RegExcmI2[0,0]\n",
    "REpI2 = (RegExcmI2[1,0] + RegExcmI2[1,1])\n",
    "REnI2 = (RegExcmI2[0,0] + RegExcmI2[0,1])\n",
    "REfpI2 = RegExcmI2[1,0]\n",
    "REfnI2 = RegExcmI2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyI2 = (REtpI2 + REtnI2) / (REpI2 + REnI2)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionI2 = REtpI2 / (REtpI2 + REfpI2)\n",
    "# recall: tp / (tp + fn)\n",
    "RErecallI2 = REtpI2 / (REtpI2 + REfnI2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1I2 = 2*REtpI2 / (2*REtpI2 + REfpI2 + REfnI2)\n",
    "\n",
    "\n",
    "REtpJL = RegExcmJL[1,1]\n",
    "REtnJL = RegExcmJL[0,0]\n",
    "REpJL = (RegExcmJL[1,0] + RegExcmJL[1,1])\n",
    "REnJL = (RegExcmJL[0,0] + RegExcmJL[0,1])\n",
    "REfpJL = RegExcmJL[1,0]\n",
    "REfnJL = RegExcmJL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyJL = (REtpJL + REtnJL) / (REpJL + REnJL)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionJL = REtpJL / (REtpJL + REfpJL)\n",
    "RErecallJL = REtpJL / (REtpJL + REfnJL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1JL = 2*REtpJL / (2*REtpJL + REfpJL + REfnJL)\n",
    "\n",
    "REtpL = RegExcmL[1,1]\n",
    "REtnL = RegExcmL[0,0]\n",
    "REpL = (RegExcmL[1,0] + RegExcmL[1,1])\n",
    "REnL = (RegExcmL[0,0] + RegExcmL[0,1])\n",
    "REfpL = RegExcmL[1,0]\n",
    "REfnL = RegExcmL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyL = (REtpL + REtnL) / (REpL + REnL)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionL = REtpL / (REtpL + REfpL)\n",
    "RErecallL = REtpL / (REtpL + REfnL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1L = 2*REtpL / (2*REtpL + REfpL + REfnL)\n",
    "\n",
    "REtpL2 = RegExcmL2[1,1]\n",
    "REtnL2 = RegExcmL2[0,0]\n",
    "REpL2 = (RegExcmL2[1,0] + RegExcmL2[1,1])\n",
    "REnL2 = (RegExcmL2[0,0] + RegExcmL2[0,1])\n",
    "REfpL2 = RegExcmL2[1,0]\n",
    "REfnL2 = RegExcmL2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "REaccuracyL2 = (REtpL2 + REtnL2) / (REpL2 + REnL2)\n",
    "# precision tp / (tp + fp)\n",
    "REprecisionL2 = REtpL2 / (REtpL2 + REfpL2)\n",
    "RErecallL2 = REtpL2 / (REtpL2 + REfnL2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "REf1L2 = 2*REtpL2 / (2*REtpL2 + REfpL2 + REfnL2)\n",
    "\n",
    "def merge(Jthresh, J2thresh): \n",
    "      \n",
    "    merged_list = [(Jthresh[i], J2thresh[i]) for i in range(0, len(Jthresh))] \n",
    "    return merged_list \n",
    "\n",
    "RegExLSA = merge(RegExthresh, LSAthresh)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "Combothresh = []\n",
    "for value in RegExLSA:\n",
    "    if value[0] or value[1] == 1:\n",
    "        Combothresh.append(1)\n",
    "    else:\n",
    "        Combothresh.append(0)\n",
    "\t\t\t\n",
    "RegExLSAI = merge(RegExthreshI, LSAthreshI)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "CombothreshI = []\n",
    "for value in RegExLSAI:\n",
    "    if value[0] or value[1] == 1:\n",
    "        CombothreshI.append(1)\n",
    "    else:\n",
    "        CombothreshI.append(0)\n",
    "\t\t\t\n",
    "RegExLSAL = merge(RegExthreshL, LSAthreshL)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "CombothreshL = []\n",
    "for value in RegExLSAL:\n",
    "    if value[0] or value[1] == 1:\n",
    "        CombothreshL.append(1)\n",
    "    else:\n",
    "        CombothreshL.append(0)\n",
    "        \n",
    "Combocm = confusion_matrix(Jthresh, Combothresh)  #confusion matrix to plug into precision and recall tool\n",
    "Ctp = Combocm[1,1]\n",
    "Ctn = Combocm[0,0]\n",
    "Cp = (Combocm[1,0] + Combocm[1,1])                    ##Combo vs Judge 1\n",
    "Cn = (Combocm[0,0] + Combocm[0,1])\n",
    "Cfp = Combocm[1,0]\n",
    "Cfn = Combocm[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "Caccuracy = (Ctp + Ctn) / (Cp + Cn)\n",
    "# precision tp / (tp + fp)\n",
    "Cprecision = Ctp / (Ctp + Cfp)\n",
    "    # recall: tp / (tp + fn)\n",
    "Crecall = Ctp / (Ctp + Cfn)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "Cf1 = 2*Ctp / (2*Ctp + Cfp + Cfn)\n",
    "    \n",
    "CombocmL2 = confusion_matrix(J2threshL, CombothreshL)  #confusion matrix to plug into precision and recall tool\n",
    "CtpL2 = CombocmL2[1,1]\n",
    "CtnL2 = CombocmL2[0,0]\n",
    "CpL2 = (CombocmL2[1,0] + CombocmL2[1,1])\n",
    "CnL2 = (CombocmL2[0,0] + CombocmL2[0,1])\n",
    "CfpL2 = CombocmL2[1,0]\n",
    "CfnL2 = CombocmL2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "CaccuracyL2 = (CtpL2 + CtnL2) / (CpL2 + CnL2)\n",
    "# precision tp / (tp + fp)\n",
    "CprecisionL2 = CtpL2 / (CtpL2 + CfpL2)\n",
    "CrecallL2 = CtpL2 / (CtpL2 + CfnL2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "Cf1L2 = 2*CtpL2 / (2*CtpL2 + CfpL2 + CfnL2)\n",
    "CombocmL = confusion_matrix(JthreshL, CombothreshL)  #confusion matrix to plug into precision and recall tool\n",
    "CtpL = CombocmL[1,1]\n",
    "CtnL = CombocmL[0,0]\n",
    "CpL = (CombocmL[1,0] + CombocmL[1,1])\n",
    "CnL = (CombocmL[0,0] + CombocmL[0,1])\n",
    "CfpL = CombocmL[1,0]\n",
    "CfnL = CombocmL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "CaccuracyL = (CtpL + CtnL) / (CpL + CnL)\n",
    "# precision tp / (tp + fp)\n",
    "CprecisionL = CtpL / (CtpL + CfpL)\n",
    "CrecallL = CtpL / (CtpL + CfnL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "Cf1L = 2*CtpL / (2*CtpL + CfpL + CfnL)\n",
    "\n",
    "CombocmI2 = confusion_matrix(J2threshI, CombothreshI)  #confusion matrix to plug into precision and recall tool\n",
    "CtpI2 = CombocmI2[1,1]\n",
    "CtnI2 = CombocmI2[0,0]\n",
    "CpI2 = (CombocmI2[1,0] + CombocmI2[1,1])\n",
    "CnI2 = (CombocmI2[0,0] + CombocmI2[0,1])\n",
    "CfpI2 = CombocmI2[1,0]\n",
    "CfnI2 = CombocmI2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "CaccuracyI2 = (CtpI2 + CtnI2) / (CpI2 + CnI2)\n",
    "# precision tp / (tp + fp)\n",
    "CprecisionI2 = CtpI2 / (CtpI2 + CfpI2)\n",
    "CrecallI2 = CtpI2 / (CtpI2 + CfnI2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "Cf1I2 = 2*CtpI2 / (2*CtpI2 + CfpI2 + CfnI2)\n",
    "\n",
    "CombocmI = confusion_matrix(JthreshI, CombothreshI)  #confusion matrix to plug into precision and recall tool\n",
    "CtpI = CombocmI[1,1]\n",
    "CtnI = CombocmI[0,0]\n",
    "CpI = (CombocmI[1,0] + CombocmI[1,1])\n",
    "CnI = (CombocmI[0,0] + CombocmI[0,1])\n",
    "CfpI = CombocmI[1,0]\n",
    "CfnI = CombocmI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "CaccuracyI = (CtpI + CtnI) / (CpI + CnI)\n",
    "# precision tp / (tp + fp)\n",
    "CprecisionI = CtpI / (CtpI + CfpI)\n",
    "CrecallI = CtpI / (CtpI + CfnI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "Cf1I = 2*CtpI / (2*CtpI + CfpI + CfnI)\n",
    "Combocm2 = confusion_matrix(J2thresh, Combothresh)  #confusion matrix to plug into precision and recall tool\n",
    "Ctp2 = Combocm2[1,1]\n",
    "Ctn2 = Combocm2[0,0]\n",
    "Cp2 = (Combocm2[1,0] + Combocm2[1,1])                    ##Combo vs Judge 1\n",
    "Cn2 = (Combocm2[0,0] + Combocm2[0,1])\n",
    "Cfp2 = Combocm2[1,0]\n",
    "Cfn2 = Combocm2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "Caccuracy2 = (Ctp2 + Ctn2) / (Cp2 + Cn2)\n",
    "# precision tp / (tp + fp)\n",
    "Cprecision2 = Ctp2 / (Ctp2 + Cfp2)\n",
    "    # recall: tp / (tp + fn)\n",
    "Crecall2 = Ctp2 / (Ctp2 + Cfn2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "Cf12 = 2*Ctp2 / (2*Ctp2 + Cfp2 + Cfn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegExLSA = merge(RegExthresh, LSAthresh)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "Combothresh = []\n",
    "for value in RegExLSA:\n",
    "    if value[0] or value[1] == 1:\n",
    "        Combothresh.append(1)\n",
    "    else:\n",
    "        Combothresh.append(0)\n",
    "\t\t\t\n",
    "RegExLSAI = merge(RegExthreshI, LSAthreshI)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "CombothreshI = []\n",
    "for value in RegExLSAI:\n",
    "    if value[0] or value[1] == 1:\n",
    "        CombothreshI.append(1)\n",
    "    else:\n",
    "        CombothreshI.append(0)\n",
    "\t\t\t\n",
    "RegExLSAL = merge(RegExthreshL, LSAthreshL)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "CombothreshL = []\n",
    "for value in RegExLSAL:\n",
    "    if value[0] or value[1] == 1:\n",
    "        CombothreshL.append(1)\n",
    "    else:\n",
    "        CombothreshL.append(0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-ea8b39d56d67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCf1L\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = EasyTable(\"My Table\")\n",
    "table.setCorners(\"/\", \"\\\\\", \"\\\\\", \"/\")\n",
    "table.setOuterStructure(\"|\", \"-\")\n",
    "table.setInnerStructure(\"|\", \"-\", \"+\")\n",
    "\n",
    "\n",
    "\n",
    "#Set the data in the table\n",
    "table.setData([\n",
    "    {\"Judge vs. LSA\": \"Stringent\", \"Kappa\": round(cohen_kappa_score(Jthresh, LSAthresh), 3), \"Precision%\": (round(precision, 3)*100), \"Recall%\": (round(recall, 3)*100), \"F1\": round(f1, 3) },\n",
    "    {\"Judge vs. LSA\": \"Intermediate\", \"Kappa\": round(cohen_kappa_score(JthreshI, LSAthreshI), 3), \"Precision%\": (round(precisionI, 3)*100), \"Recall%\": (round(recallI, 3)*100), \"F1\": round(f1I, 3)},\n",
    "    {\"Judge vs. LSA\": \"Lenient\", \"Kappa\": round(cohen_kappa_score(JthreshL, LSAthreshL), 3), \"Precision%\": (round(precisionL, 3)*100), \"Recall%\": (round(recallL, 3)*100), \"F1\": round(f1L, 3)}\n",
    "  ])\n",
    "\n",
    "#Display the table for judges/computer performance metrics\n",
    "print(\"Table for LSA vs. Judges:\")\n",
    "table.displayTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for LSA vs. Judges:\n",
      "/------------------------------------------------------\\\n",
      "|Judge vs. LSA|Kappa|Precision%|     Recall%     | F1  |\n",
      "|-------------+-----+----------+-----------------+-----|\n",
      "|  Stringent  |0.456|   46.7   |      61.8       |0.532|\n",
      "|-------------+-----+----------+-----------------+-----|\n",
      "|Intermediate |0.466|   63.6   |56.49999999999999|0.599|\n",
      "|-------------+-----+----------+-----------------+-----|\n",
      "|   Lenient   |0.46 |   71.0   |      60.4       |0.653|\n",
      "\\------------------------------------------------------/\n"
     ]
    }
   ],
   "source": [
    "table = EasyTable(\"My Table\")\n",
    "table.setCorners(\"/\", \"\\\\\", \"\\\\\", \"/\")\n",
    "table.setOuterStructure(\"|\", \"-\")\n",
    "table.setInnerStructure(\"|\", \"-\", \"+\")\n",
    "\n",
    "\n",
    "\n",
    "#Set the data in the table\n",
    "table.setData([\n",
    "    {\"J1 vs. J2\": \"Stringent\", \"Kappa\": round(cohen_kappa_score(Jthresh, J2thresh), 3), \"Precision%\": (round(precisionJ, 3)*100), \"Recall%\": (round(recallJ, 3)*100), \"F1\": round(f1J, 3) },\n",
    "    {\"J1 vs. J2\": \"Intermediate\", \"Kappa\": round(cohen_kappa_score(JthreshI, J2threshI), 3), \"Precision%\": (round(precisionJI, 3)*100), \"Recall%\": (round(recallJI, 3)*100), \"F1\": round(f1JI, 3)},\n",
    "    {\"J1 vs. J2\": \"Lenient\", \"Kappa\": round(cohen_kappa_score(JthreshL, J2threshL), 3), \"Precision%\": (round(precisionJL, 3)*100), \"Recall%\": (round(recallJL, 3)*100), \"F1\": round(f1JL, 3)}\n",
    "  ])\n",
    "\n",
    "#Display the table for judges/computer performance metrics\n",
    "print(\"Table for Judges:\")\n",
    "table.displayTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table for Combo vs. Judges:\n",
      "/-----------------------------------------------------\\\n",
      "|Judge vs. Combo|Kappa|   Precision%    |Recall%| F1  |\n",
      "|---------------+-----+-----------------+-------+-----|\n",
      "|   Stringent   |0.447|      48.0       | 58.5  |0.527|\n",
      "|---------------+-----+-----------------+-------+-----|\n",
      "| Intermediate  |0.382|57.99999999999999| 50.1  |0.538|\n",
      "|---------------+-----+-----------------+-------+-----|\n",
      "|    Lenient    |0.348|      74.3       | 50.9  |0.604|\n",
      "\\-----------------------------------------------------/\n"
     ]
    }
   ],
   "source": [
    "table = EasyTable(\"My Table\")\n",
    "table.setCorners(\"/\", \"\\\\\", \"\\\\\", \"/\")\n",
    "table.setOuterStructure(\"|\", \"-\")\n",
    "table.setInnerStructure(\"|\", \"-\", \"+\")\n",
    "\n",
    "\n",
    "\n",
    "#Set the data in the table\n",
    "table.setData([\n",
    "    {\"Judge vs. Combo\": \"Stringent\", \"Kappa\": round(cohen_kappa_score(Jthresh, Combothresh), 3), \"Precision%\": (round(Cprecision, 3)*100), \"Recall%\": (round(Crecall, 3)*100), \"F1\": round(Cf1, 3) },\n",
    "    {\"Judge vs. Combo\": \"Intermediate\", \"Kappa\": round(cohen_kappa_score(JthreshI, CombothreshI), 3), \"Precision%\": (round(CprecisionI, 3)*100), \"Recall%\": (round(CrecallI, 3)*100), \"F1\": round(Cf1I, 3)},\n",
    "    {\"Judge vs. Combo\": \"Lenient\", \"Kappa\": round(cohen_kappa_score(JthreshL, CombothreshL), 3), \"Precision%\": (round(CprecisionL, 3)*100), \"Recall%\": (round(CrecallL, 3)*100), \"F1\": round(Cf1L, 3)}\n",
    "  ])\n",
    "\n",
    "#Display the table for judges/computer performance metrics\n",
    "print(\"Table for Combo vs. Judges:\")\n",
    "table.displayTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Judge vs LSA: F1\n",
      "/---------------------------------\\\n",
      "|Judge 1 vs. LSA|LSA S|LSA I|LSA L|\n",
      "|---------------+-----+-----+-----|\n",
      "|    Judge S    |0.378|0.338|0.377|\n",
      "|---------------+-----+-----+-----|\n",
      "|    Judge I    |0.216|0.361|0.465|\n",
      "|---------------+-----+-----+-----|\n",
      "|    Judge L    |0.187|0.357|0.526|\n",
      "\\---------------------------------/\n"
     ]
    }
   ],
   "source": [
    "#Create the table and define the structure\n",
    "table = EasyTable(\"My Table\")\n",
    "table.setCorners(\"/\", \"\\\\\", \"\\\\\", \"/\")\n",
    "table.setOuterStructure(\"|\", \"-\")\n",
    "table.setInnerStructure(\"|\", \"-\", \"+\")\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "#Set the data in the table\n",
    "\n",
    "\n",
    "table.setData([\n",
    "    {\"Judge 1 vs. LSA\": \"Judge S\", \"LSA S\": round(max([listStringentJudge1][0])[0], 3), \"LSA I\": round(f1SI1, 3), \"LSA L\": round(f1SL1, 3) },\n",
    "    {\"Judge 1 vs. LSA\": \"Judge I\", \"LSA S\": round(f1IS1, 3), \"LSA I\": round(f1I, 3), \"LSA L\": round(f1IL1, 3) },\n",
    "    {\"Judge 1 vs. LSA\": \"Judge L\", \"LSA S\": round(f1LS1, 3), \"LSA I\": round(f1LI1, 3), \"LSA L\": round(f1L, 3) }\n",
    "  ])\n",
    "##Display the table\n",
    "print(\"Judge vs LSA: F1\")\n",
    "table.displayTable()\n",
    "\n",
    "#Set the data in the table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge 1 vs Judge 2: F1\n",
      "/---------------------------------------\\\n",
      "| Judges  |Judge 2 S|Judge 2 I|Judge 2 L|\n",
      "|---------+---------+---------+---------|\n",
      "|Judge 1 S|  0.532  |  0.518  |  0.47   |\n",
      "|---------+---------+---------+---------|\n",
      "|Judge 1 I|  0.495  |  0.599  |  0.569  |\n",
      "|---------+---------+---------+---------|\n",
      "|Judge 1 L|  0.421  |  0.625  |  0.653  |\n",
      "\\---------------------------------------/\n"
     ]
    }
   ],
   "source": [
    "table = EasyTable(\"My Table\")\n",
    "table.setCorners(\"/\", \"\\\\\", \"\\\\\", \"/\")\n",
    "table.setOuterStructure(\"|\", \"-\")\n",
    "table.setInnerStructure(\"|\", \"-\", \"+\")\n",
    "\n",
    "table.setData([\n",
    "    {\"Judges\":\"Judge 1 S\", \"Judge 2 S\": round(f1J, 3), \"Judge 2 I\": round(f1SI, 3), \"Judge 2 L\": round(f1SL, 3) },\n",
    "    {\"Judges\":\"Judge 1 I\", \"Judge 2 S\": round(f1IS, 3), \"Judge 2 I\": round(f1JI, 3), \"Judge 2 L\": round(f1IL, 3) },\n",
    "    {\"Judges\":\"Judge 1 L\", \"Judge 2 S\": round(f1LS, 3), \"Judge 2 I\": round(f1LI, 3), \"Judge 2 L\": round(f1JL, 3) }\n",
    "  ])\n",
    "##Display the table\n",
    "print(\"Judge 1 vs Judge 2: F1\")\n",
    "table.displayTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'reaction', 'is', 'an', 'example', 'of', 'nuclear', 'reaction', 'it', 'is', 'the', 'reaction', 'which', 'occurs', 'when', 'neutron', 'enters', 'nucleus', 'and', 'proton', 'leaves', 'the', 'nucleus', 'simultaneously', 'for', 'example', 'sulfur', 'undergoes', 'an', 'nuclear', 'reaction', 'when', 'bombarded', 'with', 'neutrons', 'thus', 'forming', 'phosphorus', 'the', 'nuclide', 'nitrogen', 'can', 'also', 'undergo', 'an', 'nuclear', 'reaction', 'to', 'produce', 'carbon', 'this', 'nuclear', 'reaction', 'continually', 'happens', 'in', 'the', 'earth', 'atmosphere', 'forming', 'equilibrium', 'amounts', 'of', 'the', 'radionuclide', 'carbon', 'most', 'reactions', 'have', 'threshold', 'neutron', 'energies', 'below', 'which', 'the', 'reaction', 'cannot', 'take', 'place', 'as', 'result', 'of', 'the', 'charged', 'particle', 'in', 'the', 'exit', 'channel', 'requiring', 'energy', 'usually', 'more', 'than', 'mev', 'to', 'overcome', 'the', 'coulomb', 'barrier', 'experienced', 'by', 'the', 'emitted', 'proton', 'the', 'nuclear', 'reaction', 'is', 'an', 'exception', 'to', 'this', 'rule', 'and', 'is', 'exothermic', 'it', 'can', 'take', 'place', 'at', 'all', 'incident', 'neutron', 'energies', 'the', 'nuclear', 'reaction', 'is', 'responsible', 'for', 'most', 'of', 'the', 'radiation', 'dose', 'delivered', 'to', 'the', 'human', 'body', 'by', 'thermal', 'neutrons', 'these', 'thermal', 'neutrons', 'are', 'absorbed', 'by', 'the', 'nitrogen', 'in', 'proteins', 'causing', 'proton', 'to', 'be', 'emitted', 'the', 'emitted', 'proton', 'deposits', 'its', 'kinetic', 'energy', 'over', 'very', 'short', 'distance', 'in', 'the', 'body', 'tissue', 'thereby', 'depositing', 'radiation', 'dose', 'references']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizedSentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79149\n",
      "Total word count in texts: 9457814\n"
     ]
    }
   ],
   "source": [
    "corpuslength = []\n",
    "for j in tokenizedSentences:\n",
    "    corpuslength.append(len(j))\n",
    "print(len(corpuslength))\n",
    "print('Total word count in texts:', sum(corpuslength))       \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:43: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "__main__:110: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "__main__:175: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "__main__:241: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "__main__:308: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "__main__:375: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "listStringentJudge1 = []\n",
    "listStringentJudge1P = []\n",
    "listStringentJudge1R = []\n",
    "ClistStringentJudge1 = []\n",
    "ClistStringentJudge1P = []\n",
    "ClistStringentJudge1R = []\n",
    "i = 0\n",
    "for value in range(1000):\n",
    "    i += .001\n",
    "    Jthresh = []                        ##the next 8 for loops are about coding match values for human judges and computer models(LSA,w2v,w2vB,D2V)\n",
    "    for value in ET.J1: \n",
    "        if value == Jthreshv: \n",
    "            Jthresh.append(1)  \n",
    "        else: \n",
    "            Jthresh.append(0)  \n",
    "    LSAthresh = [] \n",
    "    for value in df['LSAp']: \n",
    "        if value >= i: \n",
    "            LSAthresh.append(1)\n",
    "        else: \n",
    "            LSAthresh.append(0)\n",
    "    RegExLSA = merge(RegExthresh, LSAthresh)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "    Combothresh = []\n",
    "    for value in RegExLSA:\n",
    "        if value[0] or value[1] == 1:\n",
    "            Combothresh.append(1)\n",
    "        else:\n",
    "            Combothresh.append(0)\n",
    "\n",
    " \n",
    "    LSAcm = confusion_matrix(Jthresh, LSAthresh)  #confusion matrix to plug into precision and recall tool\n",
    "    tp = LSAcm[1,1]\n",
    "    tn = LSAcm[0,0]\n",
    "    p = (LSAcm[1,0] + LSAcm[1,1])                    ##LSA vs Judge 1\n",
    "    n = (LSAcm[0,0] + LSAcm[0,1])\n",
    "    fp = LSAcm[1,0]\n",
    "    fn = LSAcm[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = (tp + tn) / (p + n)\n",
    "# precision tp / (tp + fp)\n",
    "    precision = tp / (tp + fp)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = tp / (tp + fn)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = 2*tp / (2*tp + fp + fn)\n",
    "    listStringentJudge1.append((f1, i))\n",
    "    listStringentJudge1P.append((precision, i))\n",
    "    listStringentJudge1R.append((recall, i))\n",
    "    \n",
    "    Combocm = confusion_matrix(Jthresh, Combothresh)  #confusion matrix to plug into precision and recall tool\n",
    "    Ctp = Combocm[1,1]\n",
    "    Ctn = Combocm[0,0]\n",
    "    Cp = (Combocm[1,0] + Combocm[1,1])                    ##Combo vs Judge 1\n",
    "    Cn = (Combocm[0,0] + Combocm[0,1])\n",
    "    Cfp = Combocm[1,0]\n",
    "    Cfn = Combocm[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    Caccuracy = (Ctp + Ctn) / (Cp + Cn)\n",
    "# precision tp / (tp + fp)\n",
    "    Cprecision = Ctp / (Ctp + Cfp)\n",
    "    # recall: tp / (tp + fn)\n",
    "    Crecall = Ctp / (Ctp + Cfn)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    Cf1 = 2*Ctp / (2*Ctp + Cfp + Cfn)\n",
    "    ClistStringentJudge1.append((Cf1, i))\n",
    "    ClistStringentJudge1P.append((Cprecision, i))\n",
    "    ClistStringentJudge1R.append((Crecall, i))\n",
    "    \n",
    "listLenientJudge2P = []\n",
    "listLenientJudge2R = []\n",
    "listLenientJudge2 = []\n",
    "ClistLenientJudge2P = []\n",
    "ClistLenientJudge2R = []\n",
    "ClistLenientJudge2 = []\n",
    "i = 0\n",
    "for value in range(1000):\n",
    "    i += .001\n",
    "    J2threshL = [] \n",
    "    for value in ET.J2: \n",
    "        if value >= J2threshLv: \n",
    "            J2threshL.append(1)  \n",
    "        else: \n",
    "            J2threshL.append(0)     \n",
    "    LSAthreshL = [] \n",
    "    for value in df['LSAp']: \n",
    "        if value >= i: \n",
    "            LSAthreshL.append(1)\n",
    "        else: \n",
    "            LSAthreshL.append(0)\n",
    "    RegExLSAL = merge(RegExthreshL, LSAthreshL)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "    CombothreshL = []\n",
    "    for value in RegExLSAL:\n",
    "        if value[0] or value[1] == 1:\n",
    "            CombothreshL.append(1)\n",
    "        else:\n",
    "            CombothreshL.append(0)\n",
    "        \n",
    "\n",
    "    LSAcmL2 = confusion_matrix(J2threshL, LSAthreshL)  #confusion matrix to plug into precision and recall tool\n",
    "    tpL2 = LSAcmL2[1,1]\n",
    "    tnL2 = LSAcmL2[0,0]\n",
    "    pL2 = (LSAcmL2[1,0] + LSAcmL2[1,1])\n",
    "    nL2 = (LSAcmL2[0,0] + LSAcmL2[0,1])\n",
    "    fpL2 = LSAcmL2[1,0]\n",
    "    fnL2 = LSAcmL2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    accuracyL2 = (tpL2 + tnL2) / (pL2 + nL2)\n",
    "# precision tp / (tp + fp)\n",
    "    precisionL2 = tpL2 / (tpL2 + fpL2)\n",
    "    recallL2 = tpL2 / (tpL2 + fnL2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1L2 = 2*tpL2 / (2*tpL2 + fpL2 + fnL2)\n",
    "    listLenientJudge2.append((f1L2, i))\n",
    "    listLenientJudge2P.append((precisionL2, i))\n",
    "    listLenientJudge2R.append((recallL2, i))\n",
    "    \n",
    "    CombocmL2 = confusion_matrix(J2threshL, CombothreshL)  #confusion matrix to plug into precision and recall tool\n",
    "    CtpL2 = CombocmL2[1,1]\n",
    "    CtnL2 = CombocmL2[0,0]\n",
    "    CpL2 = (CombocmL2[1,0] + CombocmL2[1,1])\n",
    "    CnL2 = (CombocmL2[0,0] + CombocmL2[0,1])\n",
    "    CfpL2 = CombocmL2[1,0]\n",
    "    CfnL2 = CombocmL2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    CaccuracyL2 = (CtpL2 + CtnL2) / (CpL2 + CnL2)\n",
    "# precision tp / (tp + fp)\n",
    "    CprecisionL2 = CtpL2 / (CtpL2 + CfpL2)\n",
    "    CrecallL2 = CtpL2 / (CtpL2 + CfnL2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    Cf1L2 = 2*CtpL2 / (2*CtpL2 + CfpL2 + CfnL2)\n",
    "    ClistLenientJudge2.append((Cf1L2, i))\n",
    "    ClistLenientJudge2P.append((CprecisionL2, i))\n",
    "    ClistLenientJudge2R.append((CrecallL2, i))\n",
    "    \n",
    "listLenientJudge1P = []\n",
    "listLenientJudge1R = []\n",
    "listLenientJudge1 = []\n",
    "ClistLenientJudge1P = []\n",
    "ClistLenientJudge1R = []\n",
    "ClistLenientJudge1 = []\n",
    "i = 0\n",
    "for value in range(1000):\n",
    "    i += .001\n",
    "    JthreshL = []                        ##the next 8 for loops are about coding match values for human judges and computer models in lenient thresholds.\n",
    "    for value in ET.J1: \n",
    "        if value >= JthreshLv: \n",
    "            JthreshL.append(1)  \n",
    "        else: \n",
    "            JthreshL.append(0)   \n",
    "    LSAthreshL = [] \n",
    "    for value in df['LSAp']: \n",
    "        if value >= i: \n",
    "            LSAthreshL.append(1)\n",
    "        else: \n",
    "            LSAthreshL.append(0)\n",
    "    RegExLSAL = merge(RegExthreshL, LSAthreshL)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "    CombothreshL = []\n",
    "    for value in RegExLSAL:\n",
    "        if value[0] or value[1] == 1:\n",
    "            CombothreshL.append(1)\n",
    "        else:\n",
    "            CombothreshL.append(0)\n",
    "\n",
    "    LSAcmL = confusion_matrix(JthreshL, LSAthreshL)  #confusion matrix to plug into precision and recall tool\n",
    "    tpL = LSAcmL[1,1]\n",
    "    tnL = LSAcmL[0,0]\n",
    "    pL = (LSAcmL[1,0] + LSAcmL[1,1])\n",
    "    nL = (LSAcmL[0,0] + LSAcmL[0,1])\n",
    "    fpL = LSAcmL[1,0]\n",
    "    fnL = LSAcmL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    accuracyL = (tpL + tnL) / (pL + nL)\n",
    "# precision tp / (tp + fp)\n",
    "    precisionL = tpL / (tpL + fpL)\n",
    "    recallL = tpL / (tpL + fnL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1L = 2*tpL / (2*tpL + fpL + fnL)\n",
    "    listLenientJudge1.append((f1L, i))\n",
    "    listLenientJudge1P.append((precisionL, i))\n",
    "    listLenientJudge1R.append((recallL, i))\n",
    "    CombocmL = confusion_matrix(JthreshL, CombothreshL)  #confusion matrix to plug into precision and recall tool\n",
    "    CtpL = CombocmL[1,1]\n",
    "    CtnL = CombocmL[0,0]\n",
    "    CpL = (CombocmL[1,0] + CombocmL[1,1])\n",
    "    CnL = (CombocmL[0,0] + CombocmL[0,1])\n",
    "    CfpL = CombocmL[1,0]\n",
    "    CfnL = CombocmL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    CaccuracyL = (CtpL + CtnL) / (CpL + CnL)\n",
    "# precision tp / (tp + fp)\n",
    "    CprecisionL = CtpL / (CtpL + CfpL)\n",
    "    CrecallL = CtpL / (CtpL + CfnL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    Cf1L = 2*CtpL / (2*CtpL + CfpL + CfnL)\n",
    "    ClistLenientJudge1.append((Cf1L, i))\n",
    "    ClistLenientJudge1P.append((CprecisionL, i))\n",
    "    ClistLenientJudge1R.append((CrecallL, i))\n",
    "    \n",
    "\n",
    "listIntermediateJudge2 = []\n",
    "listIntermediateJudge2P = []\n",
    "listIntermediateJudge2R = []\n",
    "ClistIntermediateJudge2 = []\n",
    "ClistIntermediateJudge2P = []\n",
    "ClistIntermediateJudge2R = []\n",
    "i = 0\n",
    "for value in range(1000):\n",
    "    i += .001     \n",
    "    J2threshI = [] \n",
    "    for value in ET.J2: \n",
    "        if value >= J2threshIv: \n",
    "            J2threshI.append(1)  \n",
    "        else: \n",
    "            J2threshI.append(0)\n",
    "    LSAthreshI = [] \n",
    "    for value in df['LSAp']: \n",
    "        if value >= i: \n",
    "            LSAthreshI.append(1)\n",
    "        else: \n",
    "            LSAthreshI.append(0)\n",
    "    RegExLSAI = merge(RegExthreshI, LSAthreshI)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "    CombothreshI = []\n",
    "    for value in RegExLSAI:\n",
    "        if value[0] or value[1] == 1:\n",
    "            CombothreshI.append(1)\n",
    "        else:\n",
    "            CombothreshI.append(0)\n",
    "\n",
    "    LSAcmI2 = confusion_matrix(J2threshI, LSAthreshI)  #confusion matrix to plug into precision and recall tool\n",
    "    tpI2 = LSAcmI2[1,1]\n",
    "    tnI2 = LSAcmI2[0,0]\n",
    "    pI2 = (LSAcmI2[1,0] + LSAcmI2[1,1])\n",
    "    nI2 = (LSAcmI2[0,0] + LSAcmI2[0,1])\n",
    "    fpI2 = LSAcmI2[1,0]\n",
    "    fnI2 = LSAcmI2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    accuracyI2 = (tpI2 + tnI2) / (pI2 + nI2)\n",
    "# precision tp / (tp + fp)\n",
    "    precisionI2 = tpI2 / (tpI2 + fpI2)\n",
    "# recall: tp / (tp + fn)\n",
    "    recallI2 = tpI2 / (tpI2 + fnI2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1I2 = 2*tpI2 / (2*tpI2 + fpI2 + fnI2)\n",
    "    listIntermediateJudge2.append((f1I2, i))\n",
    "    listIntermediateJudge2P.append((precisionI2, i))\n",
    "    listIntermediateJudge2R.append((recallI2, i))\n",
    "    \n",
    "    CombocmI2 = confusion_matrix(J2threshI, CombothreshI)  #confusion matrix to plug into precision and recall tool\n",
    "    CtpI2 = CombocmI2[1,1]\n",
    "    CtnI2 = CombocmI2[0,0]\n",
    "    CpI2 = (CombocmI2[1,0] + CombocmI2[1,1])\n",
    "    CnI2 = (CombocmI2[0,0] + CombocmI2[0,1])\n",
    "    CfpI2 = CombocmI2[1,0]\n",
    "    CfnI2 = CombocmI2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    CaccuracyI2 = (CtpI2 + CtnI2) / (CpI2 + CnI2)\n",
    "# precision tp / (tp + fp)\n",
    "    CprecisionI2 = CtpI2 / (CtpI2 + CfpI2)\n",
    "    CrecallI2 = CtpI2 / (CtpI2 + CfnI2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    Cf1I2 = 2*CtpI2 / (2*CtpI2 + CfpI2 + CfnI2)\n",
    "    ClistIntermediateJudge2.append((Cf1I2, i))\n",
    "    ClistIntermediateJudge2P.append((CprecisionI2, i))\n",
    "    ClistIntermediateJudge2R.append((CrecallI2, i))\n",
    "\n",
    "\n",
    "listIntermediateJudge1 = []\n",
    "listIntermediateJudge1P = []\n",
    "listIntermediateJudge1R = []\n",
    "ClistIntermediateJudge1 = []\n",
    "ClistIntermediateJudge1P = []\n",
    "ClistIntermediateJudge1R = []\n",
    "i = 0\n",
    "for value in range(1000):\n",
    "    i += .001     \n",
    "    JthreshI = []                        ##the next 8 for loops are about coding match values for human judges and computer models in intermediate thresholds.\n",
    "    for value in ET.J1: \n",
    "        if value >= JthreshIv: \n",
    "            JthreshI.append(1)  \n",
    "        else: \n",
    "            JthreshI.append(0) \n",
    "    LSAthreshI = [] \n",
    "    for value in df['LSAp']: \n",
    "        if value >= i: \n",
    "            LSAthreshI.append(1)\n",
    "        else: \n",
    "            LSAthreshI.append(0) \n",
    "    RegExLSAI = merge(RegExthreshI, LSAthreshI)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "    CombothreshI = []\n",
    "    for value in RegExLSAI:\n",
    "        if value[0] or value[1] == 1:\n",
    "            CombothreshI.append(1)\n",
    "        else:\n",
    "            CombothreshI.append(0)\n",
    "\n",
    "    LSAcmI = confusion_matrix(JthreshI, LSAthreshI)  #confusion matrix to plug into precision and recall tool\n",
    "    tpI = LSAcmI[1,1]\n",
    "    tnI = LSAcmI[0,0]\n",
    "    pI = (LSAcmI[1,0] + LSAcmI[1,1])\n",
    "    nI = (LSAcmI[0,0] + LSAcmI[0,1])\n",
    "    fpI = LSAcmI[1,0]\n",
    "    fnI = LSAcmI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    accuracyI = (tpI + tnI) / (pI + nI)\n",
    "# precision tp / (tp + fp)\n",
    "    precisionI = tpI / (tpI + fpI)\n",
    "# recall: tp / (tp + fn)\n",
    "    recallI = tpI / (tpI + fnI)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1I = 2*tpI / (2*tpI + fpI + fnI)\n",
    "    listIntermediateJudge1.append((f1I, i))\n",
    "    listIntermediateJudge1R.append((recallI, i))\n",
    "    listIntermediateJudge1P.append((precisionI, i))\n",
    "    \n",
    "    CombocmI = confusion_matrix(JthreshI, CombothreshI)  #confusion matrix to plug into precision and recall tool\n",
    "    CtpI = CombocmI[1,1]\n",
    "    CtnI = CombocmI[0,0]\n",
    "    CpI = (CombocmI[1,0] + CombocmI[1,1])\n",
    "    CnI = (CombocmI[0,0] + CombocmI[0,1])\n",
    "    CfpI = CombocmI[1,0]\n",
    "    CfnI = CombocmI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    CaccuracyI = (CtpI + CtnI) / (CpI + CnI)\n",
    "# precision tp / (tp + fp)\n",
    "    CprecisionI = CtpI / (CtpI + CfpI)\n",
    "    CrecallI = CtpI / (CtpI + CfnI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    Cf1I = 2*CtpI / (2*CtpI + CfpI + CfnI)\n",
    "    ClistIntermediateJudge1.append((Cf1I, i))\n",
    "    ClistIntermediateJudge1P.append((CprecisionI, i))\n",
    "    ClistIntermediateJudge1R.append((CrecallI, i))\n",
    "    \n",
    "    \n",
    "listStringentJudge2R = []\n",
    "listStringentJudge2P = []\n",
    "listStringentJudge2 = []\n",
    "ClistStringentJudge2R = []\n",
    "ClistStringentJudge2P = []\n",
    "ClistStringentJudge2 = []\n",
    "i = 0\n",
    "for value in range(1000):\n",
    "    i += .001\n",
    "    J2thresh = [] \n",
    "    for value in ET.J2: \n",
    "        if value == J2threshv: \n",
    "            J2thresh.append(1)  \n",
    "        else: \n",
    "            J2thresh.append(0)    \n",
    "    LSAthresh = [] \n",
    "    for value in df['LSAp']: \n",
    "        if value >= i: \n",
    "            LSAthresh.append(1)\n",
    "        else: \n",
    "            LSAthresh.append(0)\n",
    "    RegExLSA = merge(RegExthresh, LSAthresh)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "    Combothresh = []\n",
    "    for value in RegExLSA:\n",
    "        if value[0] or value[1] == 1:\n",
    "            Combothresh.append(1)\n",
    "        else:\n",
    "            Combothresh.append(0)\n",
    "\n",
    "    LSAcm2 = confusion_matrix(J2thresh, LSAthresh)  #confusion matrix to plug into precision and recall tool\n",
    "    tp2 = LSAcm2[1,1]\n",
    "    tn2 = LSAcm2[0,0]\n",
    "    p2 = (LSAcm2[1,0] + LSAcm2[1,1])                    ##LSA vs Judge 2\n",
    "    n2 = (LSAcm2[0,0] + LSAcm2[0,1])\n",
    "    fp2 = LSAcm2[1,0]\n",
    "    fn2 = LSAcm2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    accuracy2 = (tp2 + tn2) / (p2 + n2)\n",
    "# precision tp / (tp + fp)\n",
    "    precision2 = tp2 / (tp2 + fp2)\n",
    "# recall: tp / (tp + fn)\n",
    "    recall2 = tp2 / (tp2 + fn2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    f12 = 2*tp2 / (2*tp2 + fp2 + fn2)\n",
    "    listStringentJudge2.append((f12, i))\n",
    "    listStringentJudge2R.append((recall2, i))\n",
    "    listStringentJudge2P.append((precision2, i))\n",
    "\n",
    "    Combocm2 = confusion_matrix(J2thresh, Combothresh)  #confusion matrix to plug into precision and recall tool\n",
    "    Ctp2 = Combocm2[1,1]\n",
    "    Ctn2 = Combocm2[0,0]\n",
    "    Cp2 = (Combocm2[1,0] + Combocm2[1,1])                    ##Combo vs Judge 1\n",
    "    Cn2 = (Combocm2[0,0] + Combocm2[0,1])\n",
    "    Cfp2 = Combocm2[1,0]\n",
    "    Cfn2 = Combocm2[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    Caccuracy2 = (Ctp2 + Ctn2) / (Cp2 + Cn2)\n",
    "# precision tp / (tp + fp)\n",
    "    Cprecision2 = Ctp2 / (Ctp2 + Cfp2)\n",
    "    # recall: tp / (tp + fn)\n",
    "    Crecall2 = Ctp2 / (Ctp2 + Cfn2)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    Cf12 = 2*Ctp2 / (2*Ctp2 + Cfp2 + Cfn2)\n",
    "    ClistStringentJudge2.append((Cf12, i))\n",
    "    ClistStringentJudge2P.append((Cprecision2, i))\n",
    "    ClistStringentJudge2R.append((Crecall2, i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listStringentJudgeB = []\n",
    "listStringentJudgeBR = []\n",
    "listStringentJudgeBP = []\n",
    "i = 0\n",
    "for value in range(1000):\n",
    "    i += .001\n",
    "    Jthresh = []                        ##the next 8 for loops are about coding match values for human judges and computer models(LSA,w2v,w2vB,D2V)\n",
    "    for value in ET.J1: \n",
    "        if value == Jthreshv: \n",
    "            Jthresh.append(1)  \n",
    "        else: \n",
    "            Jthresh.append(0) \n",
    "    J2thresh = [] \n",
    "    for value in ET.J2: \n",
    "        if value == J2threshv: \n",
    "            J2thresh.append(1)  \n",
    "        else: \n",
    "            J2thresh.append(0)    \n",
    "    LSAthresh = [] \n",
    "    for value in df['LSAp']: \n",
    "        if value >= i: \n",
    "            LSAthresh.append(1)\n",
    "        else: \n",
    "            LSAthresh.append(0)\n",
    "     # Driver \n",
    "    JudgesS = merge(Jthresh, J2thresh)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "    JBthresh = []\n",
    "    for value in JudgesS:\n",
    "        if value[0] or value[1] == 1:\n",
    "            JBthresh.append(1)\n",
    "        else:\n",
    "            JBthresh.append(0)\n",
    " \n",
    "    LSAcmJ = confusion_matrix(JBthresh, LSAthresh)\n",
    "    tpJ = LSAcmJ[1,1]\n",
    "    tnJ = LSAcmJ[0,0]\n",
    "    pJ = (LSAcmJ[1,0] + LSAcmJ[1,1])                    ##Judge vs Judge 2 stringent\n",
    "    nJ = (LSAcmJ[0,0] + LSAcmJ[0,1])\n",
    "    fpJ = LSAcmJ[1,0]\n",
    "    fnJ = LSAcmJ[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    accuracyJ = (tpJ + tnJ) / (pJ + nJ)\n",
    "# precision tp / (tp + fp)\n",
    "    precisionJ = tpJ / (tpJ + fpJ)\n",
    "# recall: tp / (tp + fn)\n",
    "\n",
    "    recallJ = tpJ / (tpJ + fnJ)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1J = 2*tpJ / (2*tpJ + fpJ + fnJ)\n",
    "    listStringentJudgeB.append((f1J, i))\n",
    "    listStringentJudgeBR.append((recallJ, i))\n",
    "    listStringentJudgeBP.append((precisionJ, i))\n",
    "    \n",
    "\n",
    "listIntermediateJudgeB = []\n",
    "listIntermediateJudgeBR = []\n",
    "listIntermediateJudgeBP = []\n",
    "i = 0\n",
    "for value in range(1000):\n",
    "    i += .001  \n",
    "    JthreshI = []                        ##the next 8 for loops are about coding match values for human judges and computer models in intermediate thresholds.\n",
    "    for value in ET.J1: \n",
    "        if value >= JthreshIv: \n",
    "            JthreshI.append(1)  \n",
    "        else: \n",
    "            JthreshI.append(0) \n",
    "    J2threshI = [] \n",
    "    for value in ET.J2: \n",
    "        if value >= J2threshIv: \n",
    "            J2threshI.append(1)  \n",
    "        else: \n",
    "            J2threshI.append(0)\n",
    "    LSAthreshI = [] \n",
    "    for value in df['LSAp']: \n",
    "        if value >= i: \n",
    "            LSAthreshI.append(1)\n",
    "        else: \n",
    "            LSAthreshI.append(0)      \n",
    "    JudgesI = merge(JthreshI, J2threshI)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "    JBthreshI = []\n",
    "    for value in JudgesI:\n",
    "        if value[0] or value[1] == 1:\n",
    "            JBthreshI.append(1)\n",
    "        else:\n",
    "            JBthreshI.append(0)\n",
    "\n",
    "    LSAcmJI = confusion_matrix(JBthreshI, LSAthreshI) \n",
    "    tpJI = LSAcmJI[1,1]\n",
    "    tnJI = LSAcmJI[0,0]\n",
    "    pJI = (LSAcmJI[1,0] + LSAcmJI[1,1])\n",
    "    nJI = (LSAcmJI[0,0] + LSAcmJI[0,1])\n",
    "    fpJI = LSAcmJI[1,0]\n",
    "    fnJI = LSAcmJI[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    accuracyJI = (tpJI + tnJI) / (pJI + nJI)\n",
    "# precision tp / (tp + fp)\n",
    "    precisionJI = tpJI / (tpJI + fpJI)\n",
    "# recall: tp / (tp + fn)\n",
    "    recallJI = tpJI / (tpJI + fnJI)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1JI = 2*tpJI / (2*tpJI + fpJI + fnJI)\n",
    "    listIntermediateJudgeB.append((f1JI, i))\n",
    "    listIntermediateJudgeBR.append((recallJI, i))\n",
    "    listIntermediateJudgeBP.append((precisionJI, i))\n",
    "    \n",
    "listLenientJudgeBR = []\n",
    "listLenientJudgeB = []\n",
    "listLenientJudgeBP = []\n",
    "i = 0\n",
    "for value in range(1000):\n",
    "    i += .001\n",
    "    JthreshL = []                        ##the next 8 for loops are about coding match values for human judges and computer models in lenient thresholds.\n",
    "    for value in ET.J1: \n",
    "        if value >= JthreshLv: \n",
    "            JthreshL.append(1)  \n",
    "        else: \n",
    "            JthreshL.append(0) \n",
    "    J2threshL = [] \n",
    "    for value in ET.J2: \n",
    "        if value >= J2threshLv: \n",
    "            J2threshL.append(1)  \n",
    "        else: \n",
    "            J2threshL.append(0)     \n",
    "    LSAthreshL = [] \n",
    "    for value in df['LSAp']: \n",
    "        if value >= i: \n",
    "            LSAthreshL.append(1)\n",
    "        else: \n",
    "            LSAthreshL.append(0)  \n",
    "     # Driver \n",
    "    JudgesL = merge(JthreshL, J2threshL)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "    JBthreshL = []\n",
    "    for value in JudgesL:\n",
    "        if value[0] or value[1] == 1:\n",
    "            JBthreshL.append(1)\n",
    "        else:\n",
    "            JBthreshL.append(0)\n",
    "\n",
    "    LSAcmJL = confusion_matrix(JBthreshL, LSAthreshL)\n",
    "    tpJL = LSAcmJL[1,1]\n",
    "    tnJL = LSAcmJL[0,0]\n",
    "    pJL = (LSAcmJL[1,0] + LSAcmJL[1,1])\n",
    "    nJL = (LSAcmJL[0,0] + LSAcmJL[0,1])\n",
    "    fpJL = LSAcmJL[1,0]\n",
    "    fnJL = LSAcmJL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    accuracyJL = (tpJL + tnJL) / (pJL + nJL)\n",
    "# precision tp / (tp + fp)\n",
    "    precisionJL = tpJL / (tpJL + fpJL)\n",
    "    recallJL = tpJL / (tpJL + fnJL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1JL = 2*tpJL / (2*tpJL + fpJL + fnJL)\n",
    "    listLenientJudgeB.append((f1JL, i))\n",
    "    listLenientJudgeBR.append((recallJL, i))\n",
    "    listLenientJudgeBP.append((precisionJL, i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.362 at .58thresh is highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = [x[1] for x in listStringentJudge1]\n",
    "y = [x[0] for x in listStringentJudge1]\n",
    "\n",
    "\n",
    "print('Judge 1 vs. LSA:')\n",
    "plt.scatter(x, y, marker=\"D\",s=.01)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## highest = f1-0.3634669151910531 @ 0.5780000000000004\n",
    "\n",
    "/---------------------------------------------------------------\\\n",
    "|Judge vs. LSA|Kappa|    Precision%    |     Recall%      | F1  |\n",
    "|-------------+-----+------------------+------------------+-----|\n",
    "|  Stringent  |0.166|60.099999999999994|       25.6       |0.359|\n",
    "|-------------+-----+------------------+------------------+-----|\n",
    "|Intermediate |0.205|       66.8       |34.599999999999994|0.456|\n",
    "|-------------+-----+------------------+------------------+-----|\n",
    "|   Lenient   |0.201|       75.4       |       42.8       |0.546|\n",
    "\\---------------------------------------------------------------/ neets+physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__main__:46: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "listLenientJudgeBP = []\n",
    "listLenientJudgeBR = []\n",
    "listLenientJudgeB = []\n",
    "i = 0\n",
    "for value in range(1000):\n",
    "    i += .001\n",
    "    JthreshL = []                        ##the next 8 for loops are about coding match values for human judges and computer models in lenient thresholds.\n",
    "    for value in ET.J1: \n",
    "        if value >= JthreshLv: \n",
    "            JthreshL.append(1)  \n",
    "        else: \n",
    "            JthreshL.append(0) \n",
    "    J2threshL = [] \n",
    "    for value in ET.J2: \n",
    "        if value >= J2threshLv: \n",
    "            J2threshL.append(1)  \n",
    "        else: \n",
    "            J2threshL.append(0)     \n",
    "    LSAthreshL = [] \n",
    "    for value in df['LSAp']: \n",
    "        if value >= i: \n",
    "            LSAthreshL.append(1)\n",
    "        else: \n",
    "            LSAthreshL.append(0)  \n",
    "     # Driver \n",
    "    JudgesL = merge(JthreshL, J2threshL)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "    JBthreshL = []\n",
    "    for value in JudgesL:\n",
    "        if value[0] or value[1] == 1:\n",
    "            JBthreshL.append(1)\n",
    "        else:\n",
    "            JBthreshL.append(0)\n",
    "\n",
    "    LSAcmJL = confusion_matrix(JBthreshL, LSAthreshL)\n",
    "    tpJL = LSAcmJL[1,1]\n",
    "    tnJL = LSAcmJL[0,0]\n",
    "    pJL = (LSAcmJL[1,0] + LSAcmJL[1,1])\n",
    "    nJL = (LSAcmJL[0,0] + LSAcmJL[0,1])\n",
    "    fpJL = LSAcmJL[1,0]\n",
    "    fnJL = LSAcmJL[0,1]\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "    accuracyJL = (tpJL + tnJL) / (pJL + nJL)\n",
    "# precision tp / (tp + fp)\n",
    "    precisionJL = tpJL / (tpJL + fpJL)\n",
    "    recallJL = tpJL / (tpJL + fnJL)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1JL = 2*tpJL / (2*tpJL + fpJL + fnJL)\n",
    "    listLenientJudgeB.append((f1JL, i))\n",
    "    listLenientJudgeBR.append((recallJL, i))\n",
    "    listLenientJudgeBP.append((precisionJL, i))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "LSA(S) vs. Judge 1- F1: (0.378076062639821, 0.44500000000000034)\n",
      "LSA(S) vs. Judge 2- F1: (0.30263726761781234, 0.47600000000000037)\n",
      "------------------------\n",
      "LSA(I) vs. Judge 1- F1: (0.46862154014798574, 0.34600000000000025)\n",
      "LSA(I) vs. Judge 2- F1: (0.4810810810810811, 0.36700000000000027)\n",
      "------------------------\n",
      "LSA(L) vs. Judge 1- F1: (0.5585152838427948, 0.2760000000000002)\n",
      "LSA(L) vs. Judge 2- F1: (0.5869848965131457, 0.19400000000000014)\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "------------------------\n",
      "COMBO(REGEX/LSA)(S) vs. Judge 1- F1: (0.5203252032520326, 0.7740000000000006)\n",
      "COMBO(REGEX/LSA)(S) vs. Judge 2- F1: (0.46586345381526106, 0.8910000000000007)\n",
      "------------------------\n",
      "COMBO(REGEX/LSA)(I) vs. Judge 1- F1: (0.5316149818767619, 0.6920000000000005)\n",
      "COMBO(REGEX/LSA)(I) vs. Judge 2- F1: (0.5061295971978984, 0.48000000000000037)\n",
      "------------------------\n",
      "COMBO(REGEX/LSA)(L) vs. Judge 1- F1: (0.6024873330262552, 0.44500000000000034)\n",
      "COMBO(REGEX/LSA)(L) vs. Judge 2- F1: (0.6140386571719226, 0.36800000000000027)\n",
      "------------------------\n",
      "Judge 1 vs. COMBO(S):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x216dca99548>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('------------------------')\n",
    "print('LSA(S) vs. Judge 1- F1:', max([(x[0], x[1]) for x in listStringentJudge1]))\n",
    "print('LSA(S) vs. Judge 2- F1:', max([(x[0], x[1]) for x in listStringentJudge2]))\n",
    "\n",
    "\n",
    "print('------------------------')\n",
    "print('LSA(I) vs. Judge 1- F1:', max([(x[0], x[1]) for x in listIntermediateJudge1]))\n",
    "print('LSA(I) vs. Judge 2- F1:', max([(x[0], x[1]) for x in listIntermediateJudge2]))\n",
    "\n",
    "\n",
    "print('------------------------')\n",
    "print('LSA(L) vs. Judge 1- F1:', max([(x[0], x[1]) for x in listLenientJudge1]))\n",
    "print('LSA(L) vs. Judge 2- F1:', max([(x[0], x[1]) for x in listLenientJudge2]))\n",
    "\n",
    "print('------------------------')\n",
    "\n",
    "\n",
    "print('------------------------')\n",
    "print('------------------------')\n",
    "print('------------------------')\n",
    "print('------------------------')\n",
    "print('------------------------')\n",
    "\n",
    "print('COMBO(REGEX/LSA)(S) vs. Judge 1- F1:', max([(x[0], x[1]) for x in ClistStringentJudge1]))\n",
    "print('COMBO(REGEX/LSA)(S) vs. Judge 2- F1:', max([(x[0], x[1]) for x in ClistStringentJudge2]))\n",
    "\n",
    "\n",
    "print('------------------------')\n",
    "print('COMBO(REGEX/LSA)(I) vs. Judge 1- F1:', max([(x[0], x[1]) for x in ClistIntermediateJudge1]))\n",
    "print('COMBO(REGEX/LSA)(I) vs. Judge 2- F1:', max([(x[0], x[1]) for x in ClistIntermediateJudge2]))\n",
    "\n",
    "\n",
    "print('------------------------')\n",
    "print('COMBO(REGEX/LSA)(L) vs. Judge 1- F1:', max([(x[0], x[1]) for x in ClistLenientJudge1]))\n",
    "print('COMBO(REGEX/LSA)(L) vs. Judge 2- F1:', max([(x[0], x[1]) for x in ClistLenientJudge2]))\n",
    "\n",
    "print('------------------------')\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x = [x[1] for x in ClistStringentJudge1]\n",
    "y = [x[0] for x in ClistStringentJudge1]\n",
    "\n",
    "\n",
    "print('Judge 1 vs. COMBO(S):')\n",
    "plt.scatter(x, y, marker=\"D\",s=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge 2 vs. LSA(S):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x207b2792148>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x = [x[1] for x in ClistStringentJudge2R]\n",
    "y = [x[0] for x in ClistStringentJudge2R]\n",
    "\n",
    "x1 = [x[1] for x in ClistStringentJudge2P]\n",
    "y1 = [x[0] for x in ClistStringentJudge2P]\n",
    "\n",
    "\n",
    "print('Judge 2 vs. LSA(S):')\n",
    "plt.scatter(x, y, marker=\"D\",s=.01)\n",
    "plt.scatter(x1, y1, marker=\"D\",s=.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge 1 vs. LSA(I):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x207b2853d08>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [x[1] for x in listIntermediateJudge1]\n",
    "y = [x[0] for x in listIntermediateJudge1]\n",
    "\n",
    "\n",
    "print('Judge 1 vs. LSA(I):')\n",
    "plt.scatter(x, y, marker=\"D\",s=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x[1] for x in listIntermediateJudge2]\n",
    "y = [x[0] for x in listIntermediateJudge2]\n",
    "\n",
    "\n",
    "print('Judge 2 vs. LSA(I):')\n",
    "plt.scatter(x, y, marker=\"D\",s=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge 1 vs. LSA(L):\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAcf0lEQVR4nO3da3Bc5Z3n8e//nO72hIRbsMC2ZMdOhsEY27ognOxsspPZqQRLtrkk2VrCLWRjbDNDdvfFVgFOwlRtMEneze4OxAhCTQzJUKlwM7Zkz9Ru7WZqAxvLsiR8TXkhYFkYZDBmgYyl7v7vC6k7LSFLR3Lf+/epUrlPnyPp/0jyr59+znOeY+6OiIhUvqDUBYiISH4o0EVEqoQCXUSkSijQRUSqhAJdRKRKxEr1jefOneuLFy8u1bcXEalIe/fuPenudZPtK1mgL168mO7u7lJ9exGRimRmr51tn4ZcRESqhAJdRKRKKNBFRKqEAl1EpEoo0EVEqoQCXUSkSijQRUSqhAJdziqdTgPg7miZZZHyp0CvAZlATqVS4z6SyeRZt4eHh9nSeYjh4WF29B1nR99xksnkWYM9nU5nPzfzQiAixVWyK0WlsNyddDpNOp1m14E3SaVSPNs7iKcdM8PdGXp/mLrzExjjt3F4+8Mk6//lIjY82cOnPvkxXh36gGd6jnNj8wLals8jCP7QF0ilUjzYdZhXhz7AzFgy9+Nsbl9KEAS4j36/3LrMjDAMS/FjEalqVqq30q2tra5L/6PLBHTm8WQhmXkMsLN/kKd7Bjj5/gjXLL6IWBjjnmsv5x8ODbH6qsuyoT7V1wnDkHQ6nT02nU7zwM6D/ObVU+NeCN7+MMmGLyxmzcoFuDtbdh7i1ZMfnPVFY95FH+ORW5oJggAzy/4rItMzs73u3jrpPgV6+Usmk+zsH+SZfcfx9NQ966H3h7n0gjl8pu587mu7IhuYwKQ95pnK9PonvhCEYZh9Lp1OZ19YJnvRSKfT3LltL2/9vzNcduEf8ZXmetY21o/r9YvI5KYKdA25FFEm5HKDLxNiyWRy0t5yKpViwxM9mBmP3nY1YRhO27M2s3FBnutce8JBEEwbvFGC+fFvrsqO7f9g1xEA2lfMJxbTn6TIbOl/zyzkDn9kticG6sR97k7ny29gZrQtn5cNsvtWX0E6neaGh1+ctNcdC2N03NZCGIZVNe6c25bNbUt5YOdBnt03yCO3No970TrbC5OIfJSGXKaQSqWAjwZ2ZvgDZ9Ihj8mC2Rj9/MVzz+N3Jz/EzFj0yT/itbd/TxiG/PjmxnG909zvWU1BfjapVIodfcfHDSvlDh0FQVATPweR6WjIZQYyIZ5MJtn45D7S6fRHQjkIguzwB0TroWdkeusTH9d6WIVhyHXNC1nbWA+MP7m7fls3gQXZ3nvu54jIH9RMoE8M0dyTdpl/0+k0G57oIZ1O887vUzy9cRWxWGzSE4kKk/ybbDrjdc0LWbNyATv7B7nzib0w9oYyCAIevf1qjbmL5KjaIZfMTItM+7r2n8DdaVs+j679J+h5/RTuzu9OfviR6XSZMVyFRfmYOG2za/8JANY21mvKo9SUmhlyyb0ickvnIV556/3sWOziT57H797+kGd6jrOk7uM0L7yI3oHTPPaN1nHT+dTzLk8TfzftK+bzYNdhVl91mcbXRcZUTQ89lUqxs3+QntdO8do7v+fG5gW0r5gPkJ0tkTvsktnWDIrKNTIywp3b9mJmdNzWomCXmlD1PfSRkREe7Dqcvay947YWYrHYtG/F9Va9ssXjcR77RiudL7/Blp2HeP3UP7P1lqZssOv3K7Wm4gP9zJkz3PXzPm5oms+alQs0b7nGxGKx7FWm97XN5c5tezn5wQgbvrCYdU0N+luQmlKxge7uDA8P89VHfsPTG1eRSCTUI6tRQRBkX8wf/+YqUqkUP9z9W8yOZxcS01CM1IKK7L6k02m27zvGXX/fx9MbVzFnzhyFeY3LvQgrkUiwuW0pe197h+v+9n+zfls3w8PD2SWCtba7VKuK66FnLqHvO/4ej9zSTDweL3VJUoZisRh/fd2K7GJimesLcleG1LRUqTYVOcslMz1R46MSVeYK4Mza7a+/8888cqs6BFJ5qm6WS2baoUhUmTH0MAy5f93y7Dj75ralGl+XqhGpi2tmq83siJkdNbN7J9n/RTM7bWa9Yx/3579UkfwIgoBYLEZTw4Xs7B/UmLpUjWkD3cxC4CGgDVgGfN3Mlk1y6D+5e9PYx3/Oc50ieZVZxvi5vjcYGRlRqEtViNJDXwUcdfdX3H0YeAq4vrBliRReLBZj681NbPpZLy/0DpBMJktdksg5iRLo9cCxnO2Bsecm+hdm1mdmXWZ21WRfyMw2mFm3mXUPDQ3NolyR/EokEjxyazM9r5/izm17GRkZKXVJIrMWJdAnO/s48f1pD/Apd28E/hvw3GRfyN073L3V3Vvr6upmVqlIgcTjcb639ipuaJrPD3YdIZlMkkqlxt0bVaQSRJnlMgAszNluAAZzD3D393Ied5rZw2Y2191P5qdMkcIKw5B1TQ2YHeeBHQf53dsfsnjuebQsupj2FfO1EqdUhCg99D3A5Wa2xMwSwE3A9twDzGyejc0jNLNVY1/37XwXK1JIQRCwtrGe1iWX0HFbCwA9r53iW3+3h/U/Hb3aNHOhkkg5mraH7u5JM7sb2A2EwOPufsDMNo3t3wp8DbjLzJLA74GbXO9VpQLlrgtz/7rlwOhSEzv7B9nwZA+LP3ne2EJgV+iiJCk7FXmlqEixZW6c0rX/BOl0muf63sguPaGL3KSYqu5KUZFiM7PsUr2ZTtDGn+3jxqYF2eV7RUpNf4UiM5BZb/+65oV03NpC78BpdvQd12wYKQsKdJFZMDPi8Tib25bSO3BagS5lQUMuIucgDENaFl2cnfmiheOklBToIufAzFh91WXcuW0viy85j+ZFF2lMXUpGf3Ui5ygWi/Ho7VfTvOgieo+d5oXeAQ3BSEko0EXyIBaLsa6pgfvaruD5/hNaE0ZKQoEukieZE6Vbb27irp/3Ze9jqitLpVg0hi6SZ4lEgh/f3MiGJ3oAWDL343xnzZW6h6kUnHroIgWQSCT4yR3X8OjtVwPwYOdh9dSl4BToIgUShiHxeJzvrl1Gy6cu1sJeUnAKdJECC8MwO7XxgR0HdWckKRgFukgRZKY2NjZcwINdhxXqUhAKdJEiCcOQMAxpariQB7sOk0qlSl2SVBmddhcpEjNjzcoFuDtmRufLb7C2sV5LBUjeqIcuUkSZ1RrbV8ynd+C0eumSVwp0kRIIw5D7Vl/Bg12azij5o0AXKZEgCDBM675I3ijQRUokCAI2ty9l14E3FeqSFwp0kRIKggB3V6BLXijQRcrAzv5BhbqcMwW6SAmZGW3L59E7cJpkMkkqlVKwy6xpHrpIiYVhyL3X/gnrf9pNEAR8paVe89NlVtRDFykDsViMf3PNIjpua8FMM19kdhToImUgcxVpZs10janLbCjQRcqEmY0bUx8ZGdFFRzIjCnSRMhOGIfd8+XJuePhFvr/jACMjI+qtSySRAt3MVpvZETM7amb3TnHcNWaWMrOv5a9EkdqTSCR4/q/+lKaGC9nwZA8v9A4o1GVa0wa6mYXAQ0AbsAz4upktO8txPwJ257tIkVoUj8e5rnkhHbe2ZKc1ikwlSg99FXDU3V9x92HgKeD6SY77NvA08FYe6xOpaWZGLBajsf4CNv5sn0JdphQl0OuBYznbA2PPZZlZPXAjsHWqL2RmG8ys28y6h4aGZlqrSE0ys2xPfdeBN3WiVM4qSqBPdnXDxMG8vwHucfcpF3d29w53b3X31rq6uqg1itS8zDrqPa+fYkffcYW6TCpKoA8AC3O2G4DBCce0Ak+Z2e+ArwEPm9kNealQRICx1RnbltI7cJodfcd1klQ+Ikqg7wEuN7MlZpYAbgK25x7g7kvcfbG7LwZ+Cfyluz+X92pFalwsFsuGunrpMtG0ge7uSeBuRmevHAJ+4e4HzGyTmW0qdIEiMl4YhjQvvIjOl99QqMs4kRbncvdOoHPCc5OeAHX3O869LBE5GzOjfcV8tnQeAtBCXpKlK0VFKlAYhnyn/Uot5CXjKNBFKlQQjP733dk/qPnpAijQRSpWZiGvva+9w53b9irURYEuUsnCMOR7a6/iKy31dO0/oZOkNU6BLlLhwjCkfcV89h17Vxcd1TgFukgVCMMwOz9dKzPWLgW6SJWIxWLct/oKnu8/ofH0GqVAF6ki8XicR25p5oe7f6tQr0EKdJEqk1lu9we7jmg8vcZEulJURCqHmbGuqYE1K9O4O+6uK0lrhHroIlWq8+U3WL+tm+37jqmnXiPUQxepQmbG2sZ6rl12KRt/ti/ba1dPvbqphy5SpcyMRCJBx60t9B1/j1RqyvvPSBVQoItUuXg8zn2rr+AHu44o1KucAl2kBoRhSFPDhezsH9R4ehVToIvUgMxCXs/2DrKj77jmqFcpBbpIjYjFYnTc2kLP66fY8ESPQr0KaZaLSA2Jx+Pcv2456XSa3Qffon3FfM18qSIKdJEaEwSB7nRUpTTkIlKjzEwnSKuMAl2kBpkZq6+6jC2dhxTqVUSBLlKjzAxDQy/VRIEuUqOCIGBz+1K69p9QqFcJBbpIDTMz9h17V8MuVUKBLlLDgiBgc9tSdh14U730KqBAF6lxQRBk102XyhYp0M1stZkdMbOjZnbvJPuvN7N+M+s1s24z+3z+SxWRQtrZP6hQr3DTBrqZhcBDQBuwDPi6mS2bcNh/BxrdvQn4d8Bj+S5URAojs85L78BprcZY4aL00FcBR939FXcfBp4Crs89wN3f9z+8tH8c0Mu8SAUJwzC7xK5OkFauKIFeDxzL2R4Ye24cM7vRzA4DOxntpYtIBckssau1XSpXlECf7Lf7kR64uz/r7kuBG4DvT/qFzDaMjbF3Dw0NzaxSESm4IAjUQ69gUQJ9AFiYs90ADJ7tYHf/FfAZM5s7yb4Od29199a6uroZFysihZNZDuDBrsMaS69QUQJ9D3C5mS0xswRwE7A99wAz+2Mbe59mZi1AAng738WKSGEFQUBTw4W6erRCTRvo7p4E7gZ2A4eAX7j7ATPbZGabxg77KrDfzHoZnRHzb11/DSIVx8xYs3JBqcuQWYq0Hrq7dwKdE57bmvP4R8CP8luaiJSCmWFmJJNJ4vF4qcuRGdCVoiIyjpnx5SvruPHHLzEyMlLqcmQGFOgi8hHxeJxn7/oc/3BoSGPpFUSBLiKTisViWuOlwijQRWRKWuOlcijQRWRSuWu8KNArgwJdRM4qDEO+036llgOoEAp0EZmSmdH58hvqpVcABbqISJVQoIvIlDJj6Rp2KX8KdBGZkruz68CbWoWxAijQRWRKmVUYtWBX+VOgi8i0zExhXgEU6CISmUK9vCnQRSQyTV8sbwp0EZmWmdG+Yr5mupQ5BbqIRBIEgUK9zCnQRWRGUqmUhl3KlAJdRCJxd3b0HWf9tm627zumUC9DCnQRicTMWNtYzyO3NPN8/wlSqVSpS5IJFOgiEpmZkUgk6Li1hd0H31Ivvcwo0EVkxsIw1N2MypACXURmTfPSy4sCXURmLDMvXcqLAl1EZsXMMDNSqZRWYiwTCnQRmRUz49pll3Lntr08sOOgQr0MKNBFZNZisRiP3n41zYsuIp1OK9RLTIEuIuckM+Nl/bZuHthxkJGRkVKXVLMiBbqZrTazI2Z21MzunWT/LWbWP/bxazNrzH+pIlKOzIx1TQ08dnsrjQ0XsOHJHpLJZKnLqkmx6Q4wsxB4CPgSMADsMbPt7n4w57BXgT9z91Nm1gZ0AJ8tRMEiUn7MjFgsxrqmBoIgoGv/CdasXEAQaBCgmKL8tFcBR939FXcfBp4Crs89wN1/7e6nxjZfAhryW6aIVILMioz7jr3Ljr7jmqNeZFECvR44lrM9MPbc2XwL6Jpsh5ltMLNuM+seGhqKXqWIVIwwDNnctpS+4+/pJGmRRQn0yRY/nvRl18z+nNFAv2ey/e7e4e6t7t5aV1cXvUoRqSixWIzNbUvZdeBN9dKLaNoxdEZ75AtzthuAwYkHmdlK4DGgzd3fzk95IlKpgiDIrveim2IUR5Qe+h7gcjNbYmYJ4CZge+4BZrYIeAa4zd1/m/8yRaRSab2X4pk20N09CdwN7AYOAb9w9wNmtsnMNo0ddj9wCfCwmfWaWXfBKhaRipBZ70WrMhZPlCEX3L0T6Jzw3Nacx+uB9fktTUSqwb5j7+LurG2s1zTGAtNPV0QKJggCNrctpXfgNDv7B9VTLzAFuogUVCwW4zvtV+rEaBEo0EWk4IIgwMw0L73AFOgiUnBmxuqrLuPBrsO6uXQBKdBFpCiCIKCp4UK69p/QWHqBKNBFpCjMjDUrF5S6jKqmQBeRosmcGFUPvTAU6CJSdLp6tDAU6CJSNJmrRwHNeCkABbqIFJWZ4e5s6TykOxvlmQJdRIoqc3K0qeFCHuw6rJ56HkVay0VEJJ+CIGBtY72uHs0z9dBFpCTMDDNjZ/+geul5okAXkZIwM9qWz2PfsXe1cFeeKNBFpGTCMMwu3JVKpdRTP0cKdBEpqSAISKfTrN/WzfdfOKBQPwcKdBEpKTNjXVMDj952dfY+pDI7CnQRKTkzIx6Ps7l9KV37T6iXPksKdBEpG2ZGz+undJJ0lhToIlI2giDIniRVoM+cAl1EykrmRtLqpc+cAl1EykpmfnrvwGkF+gwp0EWk7IRhyOa2pdneukSjn5aIlB13Z/fBtzTbZYYU6CJSdjI3ldb9R2dGgS4iZUkzXWZOgS4iZUuhPjORAt3MVpvZETM7amb3TrJ/qZm9aGZnzOw/5b9MEak1mdkuuw68qVCPaNobXJhZCDwEfAkYAPaY2XZ3P5hz2DvAvwduKEiVIlKTgiCgbfk83Qgjoig99FXAUXd/xd2HgaeA63MPcPe33H0PMFKAGkWkhrm7ltaNKMot6OqBYznbA8BnZ/PNzGwDsAFg0aJFs/kSIlJD0uk0399xgFeHPuDTdZ/gu2uXaW76FKIE+mTvdWY1oOXuHUAHQGtrqwbFRGRKQRDwvbVXkU6n6dp/QkMv04jyUjcALMzZbgAGC1OOiMh4QRAQhiFBEJBKpUpdTlmLEuh7gMvNbImZJYCbgO2FLUtE5A/MjGuXXcrGJ/cp1Kcw7ZCLuyfN7G5gNxACj7v7ATPbNLZ/q5nNA7qBC4C0mf1HYJm7v1fA2kWkhsRiMTpua9GwyxSijKHj7p1A54TntuY8PsHoUIyISMGYGVs6D3HPly8nDEPMTCdJc0QKdBGRcmBmrJj/Ca5/6NdcesEcPlN3Pve1XZEdY691CnQRqRhmxvUti1jbWA+M3gTjzif28um5mtIICnQRqTBmRiw2Gl3XNS9kzcoF2RtLm1lNj7HX9suZiFQ0MyMMQ9ydO5/Yywu9AzU9C0aBLiIVzcxY19RAx60t7Dv2Llt2HiKZTJa6rJJQoItIxTMz4vE4312zjKaFF7Kl81BN9tQV6CJSNcIwZM3KBRjGzv7BmuupK9BFpKqEYcjm9qX0vH6KDU/0cObMGVKpFKlUqurXVdcsFxGpOrFYjPvXLWdkZIQbHn6RuvMThEHIjc0LWNtYX7XTGxXoIlKVgiBgzpw5vPDtz2NmpNNpfrDrCO4+OiwzdpVpNU1zVKCLSFXLzFkPw5D7Vl/B+m3dPNNznCAI+OrVDdlwrwYKdBGpGfF4nMfvWJXddvfsBUnVMAyjQBeRmhKGIQCpVIr1P+0G4NN1n6iKNWEU6CJSk8Iw5Cd3XIO7Z9eEWXLJx9ncvjQb6pU2xm6lmsbT2trq3d3dJfneIiK53J1kMsmWnYd49eQHwGiYf6WlnrWN9WUV6ma2191bJ9unHrqI1LzMlab3X7c8O1fd3enaf4JUKlUxM2IU6CIiY3LHz9PpNHtfe4dfdh8jCAJuaJrPdc0LyzrUFegiIpMIgoD714322FOpFJt+3kvb8nkkEolSl3ZWlXs6V0SkwIIgIAxDEokEW29u4q6f9zE8PFzqss5KgS4iEkEikeDHNzeWdagr0EVEIsoN9TNnzpS6nI9QoIuIzEAikeDhr6/kq4/8ZtxKjuVAJ0VFRGZozpw5PL1xFRuf3Ie7EwQBj32jNXsVaqko0EVEZmHOnDnZK013HXgzOxsGSneFqQJdRGSWMj3y1Vddxvqfdmd76zc0zWddU0PR14VRoIuInKNYLMZP7rgGGF30a+PP9mFmtK+YDzCut+7u2SV9815HQb6qiEiNyfTWwzCk49YWtnQe4pfdxxh6f5i68xMYhrvzzu9TPHvX54jH43mvIVKgm9lq4L8AIfCYu/9wwn4b298OfAjc4e49ea5VRKQixOPx7FWm7j6uh55Op/nHwydpWz4v7+Ps0wa6mYXAQ8CXgAFgj5ltd/eDOYe1AZePfXwW+PHYvyIiNels4+dhGBYkzCHaPPRVwFF3f8Xdh4GngOsnHHM9sM1HvQRcZGbz81yriEhVKNQMmCiBXg8cy9keGHtupsdgZhvMrNvMuoeGhmZaq4iITCFKoE/2UjLxrhhRjsHdO9y91d1b6+rqotQnIiIRRQn0AWBhznYDMDiLY0REpICiBPoe4HIzW2JmCeAmYPuEY7YDt9uozwGn3f2NPNcqIiJTmHaWi7snzexuYDej0xYfd/cDZrZpbP9WoJPRKYtHGZ22+M3ClSwiIpOJNA/d3TsZDe3c57bmPHbgr/JbmoiIzISWzxURqRKWucN10b+x2RDw2iw/fS5wMo/lVAK1uTaozbXhXNr8KXefdJpgyQL9XJhZt7u3lrqOYlKba4PaXBsK1WYNuYiIVAkFuohIlajUQO8odQEloDbXBrW5NhSkzRU5hi4iIh9VqT10ERGZQIEuIlIlyjrQzWy1mR0xs6Nmdu8k+83M/uvY/n4zaylFnfkUoc23jLW138x+bWaNpagzn6Zrc85x15hZysy+Vsz6CiFKm83si2bWa2YHzOx/FbvGfIvwt32hmb1gZn1jba7oJUTM7HEze8vM9p9lf/7zK3OLpHL7YHTdmP8LfBpIAH3AsgnHtANdjC7f+zng/5S67iK0+U+Bi8cet9VCm3OO+x+MLkHxtVLXXYTf80XAQWDR2Palpa67CG3eDPxo7HEd8A6QKHXt59DmfwW0APvPsj/v+VXOPfRavFPStG1291+7+6mxzZcYXaq4kkX5PQN8G3gaeKuYxRVIlDbfDDzj7q8DuHultztKmx04f+wexZ9gNNCTxS0zf9z9V4y24Wzynl/lHOh5u1NSBZlpe77F6Ct8JZu2zWZWD9wIbKU6RPk9/wlwsZn9TzPba2a3F626wojS5r8FrmT0XgovA//B3dPFKa8k8p5fkVZbLJG83SmpgkRuj5n9OaOB/vmCVlR4Udr8N8A97p4q1L0YiyxKm2PA1cBfAB8DXjSzl9z9t4UurkCitPlaoBf418BngH80s39y9/cKXVyJ5D2/yjnQa/FOSZHaY2YrgceANnd/u0i1FUqUNrcCT42F+Vyg3cyS7v5ccUrMu6h/2yfd/QPgAzP7FdAIVGqgR2nzN4Ef+ugA81EzexVYCvymOCUWXd7zq5yHXGrxTknTttnMFgHPALdVcG8t17Rtdvcl7r7Y3RcDvwT+soLDHKL9bT8PfMHMYmZ2HvBZ4FCR68ynKG1+ndF3JJjZZcAVwCtFrbK48p5fZdtD9xq8U1LENt8PXAI8PNZjTXoFr1QXsc1VJUqb3f2Qme0C+oE08Ji7Tzr9rRJE/D1/H/g7M3uZ0eGIe9y9YpfVNbO/B74IzDWzAeCvgTgULr906b+ISJUo5yEXERGZAQW6iEiVUKCLiFQJBbqISJVQoIuIVAkFuohIlVCgi4hUif8P/ztVuiK3/hMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [x[1] for x in listLenientJudge1]\n",
    "y = [x[0] for x in listLenientJudge1]\n",
    "\n",
    "\n",
    "print('Judge 1 vs. LSA(L):')\n",
    "plt.scatter(x, y, marker=\"D\",s=.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x[1] for x in listLenientJudge2]\n",
    "y = [x[0] for x in listLenientJudge2]\n",
    "\n",
    "\n",
    "print('Judge 2 vs. LSA(L):')\n",
    "plt.scatter(x, y, marker=\"D\",s=.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "x = [x[1] for x in listStringentJudge1]\n",
    "y = [x[0] for x in listStringentJudge1]\n",
    "\n",
    "\n",
    "print('Judge 1 vs. LSA(S):')\n",
    "plt.scatter(x, y, s=.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listStringentJudge1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2a68775fc0d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x[1] for x in listLenientJudge1]\n",
    "y = [x[0] for x in listLenientJudge1]\n",
    "\n",
    "\n",
    "print('Judge 1 vs. LSA(L):')\n",
    "plt.scatter(x, y,s=.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-43240eaa40da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSansVector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlsaSpacePhys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSansBow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dim'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(JudgesS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [(0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (1, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 1), (1, 1), (0, 1), (1, 1), (1, 1), (1, 1), (0, 1), (1, 1), (1, 1), (0, 1), (1, 1), (0, 1), (0, 1), (1, 1), (0, 0), (1, 0), (0, 0), (1, 1), (1, 1), (0, 0), (1, 1), (1, 1), (1, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (1, 1), (1, 0), (0, 0), (1, 0), (0, 1), (1, 1), (0, 0), (1, 1), (0, 0), (1, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (1, 1), (1, 0), (0, 0), (1, 0), (0, 0), (0, 1), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (1, 0), (0, 0), (1, 0), (0, 0), (1, 1), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (0, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (0, 0), (1, 1), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (1, 1), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (1, 0), (1, 0), (0, 0), (1, 1), (0, 1), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (0, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (0, 0), (0, 0), (1, 1), (1, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 1), (1, 0), (0, 0), (1, 1), (0, 0), (1, 1), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (1, 1), (0, 0), (1, 1), (1, 1), (1, 0), (1, 1), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (1, 1), (1, 1), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (0, 1), (1, 0), (0, 0), (0, 0), (1, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (0, 0), (0, 0), (1, 0), (1, 1), (1, 0), (0, 0), (1, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (1, 1), (1, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 1), (0, 0), (1, 0), (1, 0), (0, 0), (1, 0), (1, 0), (0, 1), (1, 1), (1, 0), (1, 1), (0, 0), (1, 1), (0, 1), (0, 0), (1, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (1, 1), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 0), (0, 0), (1, 1), (1, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (1, 1), (0, 0), (0, 0), (0, 1), (0, 0), (1, 0), (0, 0), (0, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 0), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 0), (0, 0), (1, 1), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 1), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 1), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (1, 0), (1, 0), (1, 1), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (1, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 1), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (1, 0), (1, 0), (1, 0), (0, 0), (0, 0), (1, 0), (1, 0), (1, 0), (1, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (1, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 1), (1, 1), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (0, 1), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (1, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (0, 1), (1, 0), (1, 1), (0, 1), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (0, 0), (0, 1), (0, 1), (0, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (1, 0), (1, 1), (0, 1), (1, 0), (1, 1), (0, 1), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (1, 0), (1, 0), (0, 1), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (1, 0), (1, 0), (0, 0), (1, 0), (0, 1), (0, 1), (0, 0), (0, 0), (1, 0), (1, 1), (1, 0), (1, 0), (0, 1), (1, 0), (0, 1), (1, 0), (0, 0), (0, 0), (0, 0), (0, 1), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (0, 0), (1, 0), (1, 1), (0, 0), (1, 0), (0, 1), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (1, 0), (1, 0), (0, 1), (1, 1), (0, 1), (0, 1), (0, 1), (1, 0), (1, 0), (0, 1), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 1), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (1, 0), (1, 1), (1, 1), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (1, 0), (1, 1), (0, 1), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (1, 0), (1, 1), (1, 1), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (1, 0), (1, 1), (0, 1), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (1, 0), (1, 1), (1, 1), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (1, 0), (1, 1), (0, 1), (1, 0), (0, 1), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 1), (1, 0), (0, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 1), (1, 0), (1, 1), (1, 1), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 1), (0, 0), (1, 0), (0, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (0, 0), (1, 0), (1, 0), (0, 1), (0, 0), (0, 0), (1, 0), (1, 1), (1, 1), (0, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (0, 1), (1, 0), (1, 1), (1, 1), (1, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (0, 1), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (1, 0), (0, 1), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 1), (0, 0), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 1), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (0, 1), (1, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (1, 0), (0, 1), (1, 0), (0, 0), (0, 0), (1, 0), (0, 1), (0, 0), (1, 0), (0, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 1), (1, 0), (0, 1), (1, 0), (0, 1), (0, 0), (1, 0), (0, 1), (0, 0), (1, 0), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (1, 1), (1, 0), (1, 1), (0, 0), (1, 0), (0, 0), (1, 0), (1, 1), (0, 1), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 1), (1, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (1, 1), (1, 0), (0, 0), (1, 1), (1, 1), (0, 0), (1, 1), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (1, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 1), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 1), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 1), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (1, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 1), (0, 0), (1, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 1), (0, 1), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (1, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (1, 1), (1, 1), (0, 0), (1, 1), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (1, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (1, 1), (0, 1), (0, 0), (1, 1), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (1, 0), (0, 1), (0, 1), (1, 1), (1, 1), (1, 1), (0, 0), (1, 1), (1, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 1), (0, 0), (1, 1), (0, 1), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (1, 0), (0, 0), (1, 0), (0, 0), (1, 1), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (1, 1), (1, 1), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 1), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 1), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (1, 0), (1, 0), (0, 0), (1, 0), (0, 0), (1, 0), (1, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (1, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]\n"
     ]
    }
   ],
   "source": [
    "Jthreshv = 6\n",
    "J2threshv = 6\n",
    "LSAthreshv = .506   #Stringent(S) thresholds .58\n",
    "\n",
    "JthreshIv = 5\n",
    "J2threshIv = 5\n",
    "LSAthreshIv = .4  #Intermediate(I) thresholds .509 = .443f1 or .515\n",
    "\n",
    "JthreshLv = 4\n",
    "J2threshLv = 4\n",
    "LSAthreshLv = .27 #Lenient(L) thresholds(.369 and .42,.427,,428=.538) (.366=.357) .29 and .355 is .536 (.35,.535)\n",
    "\n",
    "JudgesS = ()\n",
    "Jthresh = []                        ##the next 8 for loops are about coding match values for human judges and computer models(LSA,w2v,w2vB,D2V)\n",
    "for value in ET.J1: \n",
    "    if value == Jthreshv: \n",
    "        Jthresh.append(1)  \n",
    "    else: \n",
    "        Jthresh.append(0) \n",
    "J2thresh = [] \n",
    "for value in ET.J2: \n",
    "    if value == J2threshv: \n",
    "        J2thresh.append(1)  \n",
    "    else: \n",
    "        J2thresh.append(0)    \n",
    "LSAthresh = [] \n",
    "for value in df['LSAp']: \n",
    "    if value >= LSAthreshv: \n",
    "        LSAthresh.append(1)\n",
    "    else: \n",
    "        LSAthresh.append(0)\n",
    "\n",
    "def merge(Jthresh, J2thresh): \n",
    "      \n",
    "    merged_list = [(Jthresh[i], J2thresh[i]) for i in range(0, len(Jthresh))] \n",
    "    return merged_list \n",
    "      \n",
    "# Driver \n",
    "JudgesS = merge(Jthresh, J2thresh)           ##Very important. Used for Judges either/or as well as LSA/RegEx combination thresholds.\n",
    "JBthresh = []\n",
    "for value in JudgesS:\n",
    "    if value[0] or value[1] == 1:\n",
    "        JBthresh.append(1)\n",
    "    else:\n",
    "        JBthresh.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'tuple' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d9e9640b1546>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJthresh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ2thresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mJudgesS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'tuple' and 'float'"
     ]
    }
   ],
   "source": [
    "JudgesS = []\n",
    "i = 0\n",
    "while i <= len(Jthresh): \n",
    "    i += 1\n",
    "    for value in [(Jthresh, J2thresh)]:\n",
    "        if value >= .5:\n",
    "            JudgesS.join(1)\n",
    "        else:\n",
    "            JudgesS.join(0)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA(S) vs. Judge 2: (0.29456668163448585, 0.47500000000000037)\n"
     ]
    }
   ],
   "source": [
    "print('LSA(S) vs. Judge 2:', max([(x[0], x[1]) for x in listStringentJudge2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5753679318357862, 0.001), (0.5754276827371695, 0.002), (0.5746910683560144, 0.003), (0.575962293794187, 0.004), (0.5767955801104973, 0.005), (0.579047619047619, 0.006), (0.579585326953748, 0.007), (0.581223966677347, 0.008), (0.5816835667149525, 0.009000000000000001), (0.5820413436692506, 0.010000000000000002), (0.5824834061842318, 0.011000000000000003), (0.5832115603182335, 0.012000000000000004), (0.5831435079726651, 0.013000000000000005), (0.5842036553524804, 0.014000000000000005), (0.5844092171923517, 0.015000000000000006), (0.5851098720892096, 0.016000000000000007), (0.5853899308983218, 0.017000000000000008), (0.5856553998351195, 0.01800000000000001), (0.585962014863749, 0.01900000000000001), (0.5866004962779157, 0.02000000000000001), (0.5868124585818423, 0.02100000000000001), (0.5872778608204617, 0.022000000000000013), (0.5877265923831698, 0.023000000000000013), (0.5869021829695051, 0.024000000000000014), (0.5870364183093886, 0.025000000000000015), (0.5875062803550494, 0.026000000000000016), (0.5882155447372839, 0.027000000000000017), (0.5889281507656066, 0.028000000000000018), (0.5890087660148348, 0.02900000000000002), (0.5893279297534617, 0.03000000000000002), (0.5889715832205683, 0.03100000000000002), (0.5885540128682696, 0.03200000000000002), (0.5888135593220339, 0.03300000000000002), (0.5888342100797557, 0.03400000000000002), (0.5893949694085656, 0.035000000000000024), (0.589416368895695, 0.036000000000000025), (0.5893374212229603, 0.037000000000000026), (0.5898397545175588, 0.03800000000000003), (0.5894808743169399, 0.03900000000000003), (0.5899846180140147, 0.04000000000000003), (0.589041095890411, 0.04100000000000003), (0.5895458440445587, 0.04200000000000003), (0.5900514579759862, 0.04300000000000003), (0.5898712446351931, 0.04400000000000003), (0.5905024088093599, 0.04500000000000003), (0.5909717436250862, 0.046000000000000034), (0.5909953424184923, 0.047000000000000035), (0.5902885778468983, 0.048000000000000036), (0.5905552672548002, 0.04900000000000004), (0.5909248354693454, 0.05000000000000004), (0.5909485000867002, 0.05100000000000004), (0.5912560721721027, 0.05200000000000004), (0.5918331885317115, 0.05300000000000004), (0.5911621433542101, 0.05400000000000004), (0.592295624891058, 0.05500000000000004), (0.5925667422788344, 0.05600000000000004), (0.5925925925925926, 0.057000000000000044), (0.5929296464823242, 0.058000000000000045), (0.5928909122745579, 0.059000000000000045), (0.5927094286715738, 0.060000000000000046), (0.5924885924885925, 0.06100000000000005), (0.593282925971514, 0.06200000000000005), (0.5935574722760077, 0.06300000000000004), (0.5932980599647266, 0.06400000000000004), (0.5933639251676668, 0.06500000000000004), (0.5936395759717314, 0.06600000000000004), (0.5941644562334217, 0.06700000000000005), (0.594585029198372, 0.06800000000000005), (0.593905031892275, 0.06900000000000005), (0.5938275984391628, 0.07000000000000005), (0.5938554430829338, 0.07100000000000005), (0.593672236046925, 0.07200000000000005), (0.5934887030777442, 0.07300000000000005), (0.5926981300089047, 0.07400000000000005), (0.5917602996254682, 0.07500000000000005), (0.591971454058876, 0.07600000000000005), (0.5916800571326549, 0.07700000000000005), (0.5913882437019832, 0.07800000000000006), (0.591493924231594, 0.07900000000000006), (0.5915996425379804, 0.08000000000000006), (0.5910148559155182, 0.08100000000000006), (0.5911859548548907, 0.08200000000000006), (0.5913978494623656, 0.08300000000000006), (0.5916352539938969, 0.08400000000000006), (0.5916352539938969, 0.08500000000000006), (0.5918074020840819, 0.08600000000000006), (0.5919137466307277, 0.08700000000000006), (0.5921265504224339, 0.08800000000000006), (0.5923395072828628, 0.08900000000000007), (0.5919395465994962, 0.09000000000000007), (0.5913920403385557, 0.09100000000000007), (0.5908435472242249, 0.09200000000000007), (0.5909500630971697, 0.09300000000000007), (0.5906959971150378, 0.09400000000000007), (0.5910156954717662, 0.09500000000000007), (0.5911472448057814, 0.09600000000000007), (0.5911472448057814, 0.09700000000000007), (0.591534008683068, 0.09800000000000007), (0.5915595000905634, 0.09900000000000007), (0.5904969169387014, 0.10000000000000007), (0.5900925421883506, 0.10100000000000008), (0.5901579807517705, 0.10200000000000008), (0.5905454545454546, 0.10300000000000008), (0.5905039112243041, 0.10400000000000008), (0.5902296755377324, 0.10500000000000008), (0.5910916392844103, 0.10600000000000008), (0.591374269005848, 0.10700000000000008), (0.5909257226491036, 0.10800000000000008), (0.5913584767484438, 0.10900000000000008), (0.590692561377794, 0.11000000000000008), (0.5909090909090909, 0.11100000000000008), (0.5914511098880939, 0.11200000000000009), (0.591776798825257, 0.11300000000000009), (0.5919941241278002, 0.11400000000000009), (0.5918442321822189, 0.11500000000000009), (0.5919117647058824, 0.11600000000000009), (0.5919793966151582, 0.11700000000000009), (0.5920883164673413, 0.11800000000000009), (0.5925925925925926, 0.11900000000000009), (0.592551622418879, 0.12000000000000009), (0.5926473305006466, 0.1210000000000001), (0.5916743755781684, 0.1220000000000001), (0.5916327286190299, 0.1230000000000001), (0.5915910353769217, 0.1240000000000001), (0.591246290801187, 0.12500000000000008), (0.5914656771799629, 0.12600000000000008), (0.5914237980322999, 0.12700000000000009), (0.5915336056442629, 0.12800000000000009), (0.5916697657121607, 0.1290000000000001), (0.5921787709497207, 0.1300000000000001), (0.5919850885368126, 0.1310000000000001), (0.5917910447761194, 0.1320000000000001), (0.5912231559290383, 0.1330000000000001), (0.5911808669656203, 0.1340000000000001), (0.5914702581369248, 0.1350000000000001), (0.5914280366835112, 0.1360000000000001), (0.5908579992506556, 0.1370000000000001), (0.5906191369606004, 0.1380000000000001), (0.5902686455006575, 0.1390000000000001), (0.590379556557685, 0.1400000000000001), (0.5904905093027626, 0.1410000000000001), (0.5894538606403014, 0.1420000000000001), (0.5894538606403014, 0.1430000000000001), (0.5894102129263237, 0.1440000000000001), (0.5894776541580238, 0.1450000000000001), (0.5889014722536806, 0.1460000000000001), (0.589012648669058, 0.1470000000000001), (0.5881240544629349, 0.1480000000000001), (0.5877674682825222, 0.1490000000000001), (0.587833996588971, 0.1500000000000001), (0.5877891543420554, 0.1510000000000001), (0.587744261051034, 0.1520000000000001), (0.588034188034188, 0.1530000000000001), (0.5881011214597985, 0.1540000000000001), (0.5877426722497145, 0.1550000000000001), (0.5878095238095238, 0.1560000000000001), (0.5879885605338417, 0.1570000000000001), (0.5878984539034167, 0.1580000000000001), (0.588460068781047, 0.1590000000000001), (0.5885725205427097, 0.16000000000000011), (0.5879877582249426, 0.16100000000000012), (0.5890017244682889, 0.16200000000000012), (0.5883029721955897, 0.16300000000000012), (0.5878741366078281, 0.16400000000000012), (0.5873320537428023, 0.16500000000000012), (0.5872863453043979, 0.16600000000000012), (0.5878053471821504, 0.16700000000000012), (0.5877142306951666, 0.16800000000000012), (0.5874638379942141, 0.16900000000000012), (0.5873046498167085, 0.17000000000000012), (0.5875313646014283, 0.17100000000000012), (0.5874855156431055, 0.17200000000000013), (0.58743961352657, 0.17300000000000013), (0.5873936581593194, 0.17400000000000013), (0.5872340425531914, 0.17500000000000013), (0.5873015873015873, 0.17600000000000013), (0.5878247382706475, 0.17700000000000013), (0.5876648564778898, 0.17800000000000013), (0.5877329192546584, 0.17900000000000013), (0.587686929500874, 0.18000000000000013), (0.5876408861251458, 0.18100000000000013), (0.5874805598755832, 0.18200000000000013), (0.5875947890336379, 0.18300000000000013), (0.5882810979170722, 0.18400000000000014), (0.5875706214689266, 0.18500000000000014), (0.5872024970737417, 0.18600000000000014), (0.587890625, 0.18700000000000014), (0.588304322315666, 0.18800000000000014), (0.5883734586024663, 0.18900000000000014), (0.5886733294140701, 0.19000000000000014), (0.5885815185403178, 0.19100000000000014), (0.5882121807465619, 0.19200000000000014), (0.5877952755905512, 0.19300000000000014), (0.5882121032919377, 0.19400000000000014), (0.588119202684034, 0.19500000000000015), (0.5885375494071147, 0.19600000000000015), (0.5882818685669042, 0.19700000000000015), (0.5880023757671748, 0.19800000000000015), (0.5883052527254707, 0.19900000000000015), (0.5882119468148442, 0.20000000000000015), (0.5882820258192651, 0.20100000000000015), (0.5876739562624255, 0.20200000000000015), (0.5869478710704338, 0.20300000000000015), (0.5859593139210212, 0.20400000000000015), (0.5860279441117765, 0.20500000000000015), (0.5856971634039153, 0.20600000000000016), (0.585765693722511, 0.20700000000000016), (0.5857171434286857, 0.20800000000000016), (0.5856885147324113, 0.20900000000000016), (0.5848563968668408, 0.21000000000000016), (0.5850914205344585, 0.21100000000000016), (0.5855130784708249, 0.21200000000000016), (0.5850120870265915, 0.21300000000000016), (0.58484482063684, 0.21400000000000016), (0.5850312689126488, 0.21500000000000016), (0.5848142164781907, 0.21600000000000016), (0.5847645989088704, 0.21700000000000016), (0.5844287158746209, 0.21800000000000017), (0.5849018417324429, 0.21900000000000017), (0.5832995541143089, 0.22000000000000017), (0.5826739703793873, 0.22100000000000017), (0.5825045666734321, 0.22200000000000017), (0.5826228177019894, 0.22300000000000017), (0.5819438796258641, 0.22400000000000017), (0.5823661168804725, 0.22500000000000017), (0.5815139767394409, 0.22600000000000017), (0.5812908496732027, 0.22700000000000017), (0.5808958887298016, 0.22800000000000017), (0.5804997951659157, 0.22900000000000018), (0.5805658056580566, 0.23000000000000018), (0.5803937653814603, 0.23100000000000018), (0.5801025641025641, 0.23200000000000018), (0.5804597701149425, 0.23300000000000018), (0.580115036976171, 0.23400000000000018), (0.579888957433683, 0.23500000000000018), (0.5807248764415156, 0.23600000000000018), (0.5812706270627063, 0.23700000000000018), (0.5822314049586776, 0.23800000000000018), (0.5820062047569804, 0.23900000000000018), (0.5815544041450778, 0.24000000000000019), (0.5819162173372044, 0.2410000000000002), (0.5820369218004563, 0.2420000000000002), (0.5831946755407654, 0.2430000000000002), (0.5835587929240375, 0.2440000000000002), (0.5841150719199499, 0.2450000000000002), (0.5844806007509387, 0.2460000000000002), (0.5835421888053467, 0.2470000000000002), (0.582723279648609, 0.2480000000000002), (0.5829145728643216, 0.2490000000000002), (0.5826178010471205, 0.25000000000000017), (0.5822147651006712, 0.25100000000000017), (0.5818793357157873, 0.25200000000000017), (0.582124079915878, 0.25300000000000017), (0.5816498316498316, 0.25400000000000017), (0.582086406743941, 0.25500000000000017), (0.5821556633621598, 0.25600000000000017), (0.5812038014783527, 0.2570000000000002), (0.58194121378727, 0.2580000000000002), (0.582010582010582, 0.2590000000000002), (0.5816023738872403, 0.2600000000000002), (0.5804670912951168, 0.2610000000000002), (0.579562353940939, 0.2620000000000002), (0.580302063390768, 0.2630000000000002), (0.5802469135802469, 0.2640000000000002), (0.5801364023870418, 0.2650000000000002), (0.5803837953091684, 0.2660000000000002), (0.5797906430249946, 0.2670000000000002), (0.5798031664527171, 0.2680000000000002), (0.5798157274480394, 0.2690000000000002), (0.5787215787215787, 0.2700000000000002), (0.5793429246295899, 0.2710000000000002), (0.5789247311827957, 0.2720000000000002), (0.5792984721325587, 0.2730000000000002), (0.5783236371471666, 0.2740000000000002), (0.5775285745093811, 0.2750000000000002), (0.5777777777777777, 0.2760000000000002), (0.5770477631294575, 0.2770000000000002), (0.5766818083495565, 0.2780000000000002), (0.5763152197445335, 0.2790000000000002), (0.5762564991334489, 0.2800000000000002), (0.5754614549402823, 0.2810000000000002), (0.5751577115510115, 0.2820000000000002), (0.5753484320557491, 0.2830000000000002), (0.5753544165757907, 0.2840000000000002), (0.5750491588376666, 0.2850000000000002), (0.5759964958388086, 0.2860000000000002), (0.5753124314843236, 0.2870000000000002), (0.5748792270531401, 0.2880000000000002), (0.5743792573060865, 0.2890000000000002), (0.5726872246696035, 0.2900000000000002), (0.5731303772336201, 0.2910000000000002), (0.572628786203847, 0.2920000000000002), (0.5726930736888692, 0.2930000000000002), (0.5722517730496454, 0.2940000000000002), (0.5714285714285714, 0.2950000000000002), (0.5705398800266608, 0.2960000000000002), (0.5708565072302558, 0.2970000000000002), (0.5716195143684563, 0.2980000000000002), (0.5718743035435703, 0.2990000000000002), (0.57091802546348, 0.3000000000000002), (0.5703422053231939, 0.3010000000000002), (0.5698924731182796, 0.3020000000000002), (0.569572036746583, 0.3030000000000002), (0.5691859161246916, 0.3040000000000002), (0.5685438635853713, 0.3050000000000002), (0.5683501683501684, 0.3060000000000002), (0.5684731279514279, 0.3070000000000002), (0.5673120216118865, 0.3080000000000002), (0.5671171171171171, 0.3090000000000002), (0.5665990534144693, 0.3100000000000002), (0.5656200587305172, 0.3110000000000002), (0.5650305360778104, 0.3120000000000002), (0.563858695652174, 0.3130000000000002), (0.5631376105191567, 0.3140000000000002), (0.5633227417158421, 0.3150000000000002), (0.5623293903548681, 0.3160000000000002), (0.5619872379216043, 0.3170000000000002), (0.5622435020519836, 0.3180000000000002), (0.5623003194888179, 0.31900000000000023), (0.5626142595978062, 0.32000000000000023), (0.5622857142857143, 0.32100000000000023), (0.5628002745367193, 0.32200000000000023), (0.5630444750114626, 0.32300000000000023), (0.5627725499196695, 0.32400000000000023), (0.5631603123564538, 0.32500000000000023), (0.563017479300828, 0.32600000000000023), (0.5630755064456722, 0.32700000000000023), (0.5622119815668203, 0.32800000000000024), (0.5624711848778239, 0.32900000000000024), (0.5619377162629757, 0.33000000000000024), (0.5608685608685609, 0.33100000000000024), (0.5611843627110803, 0.33200000000000024), (0.5608907446068198, 0.33300000000000024), (0.5604829347573718, 0.33400000000000024), (0.5603348058591026, 0.33500000000000024), (0.5604472396925227, 0.33600000000000024), (0.5603729603729604, 0.33700000000000024), (0.5600933488914819, 0.33800000000000024), (0.5593457943925234, 0.33900000000000025), (0.5593260004680553, 0.34000000000000025), (0.55917506444809, 0.34100000000000025), (0.5583470298192064, 0.34200000000000025), (0.5582706766917294, 0.34300000000000025), (0.5579863561514937, 0.34400000000000025), (0.5578327444051826, 0.34500000000000025), (0.5561850802644004, 0.34600000000000025), (0.5563696525644056, 0.34700000000000025), (0.5562913907284768, 0.34800000000000025), (0.5554502369668246, 0.34900000000000025), (0.555239449976292, 0.35000000000000026), (0.5555555555555556, 0.35100000000000026), (0.5550011879306248, 0.35200000000000026), (0.555397051830718, 0.35300000000000026), (0.5554497858162779, 0.35400000000000026), (0.5552380952380952, 0.35500000000000026), (0.5547340806105414, 0.35600000000000026), (0.5541766109785203, 0.35700000000000026), (0.5542283803153368, 0.35800000000000026), (0.5538535184298707, 0.35900000000000026), (0.5534259702922856, 0.36000000000000026), (0.5532629558541267, 0.36100000000000027), (0.553314121037464, 0.36200000000000027), (0.5533653846153846, 0.36300000000000027), (0.5523717794365519, 0.36400000000000027), (0.5524222704266089, 0.36500000000000027), (0.552821997105644, 0.36600000000000027), (0.5529753265602322, 0.36700000000000027), (0.5537790697674418, 0.36800000000000027), (0.553562772661173, 0.36900000000000027), (0.553831231813773, 0.3700000000000003), (0.5536668285575522, 0.3710000000000003), (0.5533673717481157, 0.3720000000000003), (0.5535019455252919, 0.3730000000000003), (0.5530671859785784, 0.3740000000000003), (0.5521442495126706, 0.3750000000000003), (0.552817760429373, 0.3760000000000003), (0.552297165200391, 0.3770000000000003), (0.5526186979931473, 0.3780000000000003), (0.5512506130456106, 0.3790000000000003), (0.5499631721090106, 0.3800000000000003), (0.549520766773163, 0.3810000000000003), (0.5488074747971478, 0.3820000000000003), (0.5484982767109798, 0.3830000000000003), (0.5492227979274611, 0.3840000000000003), (0.5497653741664609, 0.3850000000000003), (0.5483312731767614, 0.3860000000000003), (0.5484668644906033, 0.3870000000000003), (0.5482912332838039, 0.3880000000000003), (0.5474888115365489, 0.3890000000000003), (0.5470383275261324, 0.3900000000000003), (0.5460886895864474, 0.3910000000000003), (0.5460444222610432, 0.3920000000000003), (0.545272636318159, 0.3930000000000003), (0.5456821026282853, 0.3940000000000003), (0.5455001253446979, 0.3950000000000003), (0.5447686116700201, 0.3960000000000003), (0.5443101711983888, 0.3970000000000003), (0.5438508064516129, 0.3980000000000003), (0.5435276305828918, 0.3990000000000003), (0.5432971471850543, 0.4000000000000003), (0.5432971471850543, 0.4010000000000003), (0.5430664309168982, 0.4020000000000003), (0.5423300480161739, 0.4030000000000003), (0.5421839371674689, 0.4040000000000003), (0.5422267309155465, 0.4050000000000003), (0.5425450850901702, 0.4060000000000003), (0.5405955713922117, 0.4070000000000003), (0.5387755102040817, 0.4080000000000003), (0.5384418901660281, 0.4090000000000003), (0.5363357215967247, 0.4100000000000003), (0.5357234314980794, 0.4110000000000003), (0.5354855239559313, 0.4120000000000003), (0.5354209445585215, 0.4130000000000003), (0.5338133196194395, 0.4140000000000003), (0.533470648815654, 0.4150000000000003), (0.5335051546391752, 0.4160000000000003), (0.5318874257681384, 0.4170000000000003), (0.5319534282018111, 0.4180000000000003), (0.5312257061414875, 0.4190000000000003), (0.5312581063553826, 0.4200000000000003), (0.5305274097168096, 0.4210000000000003), (0.5305909919291851, 0.4220000000000003), (0.5298565840938723, 0.4230000000000003), (0.5291198746408984, 0.4240000000000003), (0.5282722513089005, 0.4250000000000003), (0.527916120576671, 0.4260000000000003), (0.5267576075550892, 0.4270000000000003), (0.5251249671139174, 0.4280000000000003), (0.5247629083245522, 0.4290000000000003), (0.525065963060686, 0.4300000000000003), (0.5236709865115049, 0.4310000000000003), (0.5232804232804232, 0.43200000000000033), (0.5228896533474464, 0.43300000000000033), (0.5212089077412513, 0.43400000000000033), (0.5210931281507031, 0.43500000000000033), (0.5203295243157056, 0.43600000000000033), (0.5198191008246874, 0.43700000000000033), (0.5193075898801598, 0.43800000000000033), (0.5197228144989339, 0.43900000000000033), (0.5189535504538174, 0.44000000000000034), (0.5188553089061246, 0.44100000000000034), (0.5163538873994639, 0.44200000000000034), (0.5154528352593389, 0.44300000000000034), (0.5163028833198599, 0.44400000000000034), (0.5165991902834008, 0.44500000000000034), (0.5167567567567568, 0.44600000000000034), (0.5154304277206281, 0.44700000000000034), (0.5147656461663506, 0.44800000000000034), (0.5138361367335865, 0.44900000000000034), (0.5125, 0.45000000000000034), (0.5115898554676848, 0.45100000000000035), (0.5113357006282436, 0.45200000000000035), (0.5099972610243769, 0.45300000000000035), (0.5090510148107515, 0.45400000000000035), (0.5089212187757343, 0.45500000000000035), (0.5070112730272203, 0.45600000000000035), (0.5070189925681255, 0.45700000000000035), (0.5066079295154186, 0.45800000000000035), (0.5063430777716492, 0.45900000000000035), (0.5045592705167173, 0.46000000000000035), (0.5042853193254078, 0.46100000000000035), (0.5023539185821102, 0.46200000000000035), (0.5030538589672404, 0.46300000000000036), (0.5027777777777778, 0.46400000000000036), (0.5030572540300167, 0.46500000000000036), (0.5023643949930459, 0.46600000000000036), (0.501949860724234, 0.46700000000000036), (0.500976290097629, 0.46800000000000036), (0.5, 0.46900000000000036), (0.4987405541561713, 0.47000000000000036), (0.4980392156862745, 0.47100000000000036), (0.4974733295901179, 0.47200000000000036), (0.49620679966282666, 0.47300000000000036), (0.49634214969048956, 0.47400000000000037), (0.4954954954954955, 0.47500000000000037), (0.4939385396109388, 0.47600000000000037), (0.4928027095681626, 0.47700000000000037), (0.4927864214992928, 0.47800000000000037), (0.49206349206349204, 0.47900000000000037), (0.49176604202157864, 0.48000000000000037), (0.489749430523918, 0.48100000000000037), (0.4887368120901055, 0.4820000000000004), (0.48758207250927776, 0.4830000000000004), (0.4872748069774092, 0.4840000000000004), (0.48623853211009177, 0.4850000000000004), (0.4865174985656913, 0.4860000000000004), (0.48563218390804597, 0.4870000000000004), (0.48519689565967233, 0.4880000000000004), (0.48474381116868165, 0.4890000000000004), (0.4839919238534756, 0.4900000000000004), (0.484393063583815, 0.4910000000000004), (0.4831981460023175, 0.4920000000000004), (0.4834590829947766, 0.4930000000000004), (0.48255813953488375, 0.4940000000000004), (0.48121176813282845, 0.4950000000000004), (0.4803034724248614, 0.4960000000000004), (0.47969617294770667, 0.4970000000000004), (0.47939199064600996, 0.4980000000000004), (0.47950819672131145, 0.4990000000000004), (0.4781716964547319, 0.5000000000000003), (0.4764982373678026, 0.5010000000000003), (0.47571386517515457, 0.5020000000000003), (0.4761343547436653, 0.5030000000000003), (0.47520661157024796, 0.5040000000000003), (0.47368421052631576, 0.5050000000000003), (0.4740740740740741, 0.5060000000000003), (0.47240356083086055, 0.5070000000000003), (0.47296494355317886, 0.5080000000000003), (0.472197442759441, 0.5090000000000003), (0.47065832588620793, 0.5100000000000003), (0.4693938489101224, 0.5110000000000003), (0.4681233163723436, 0.5120000000000003), (0.46794487717195926, 0.5130000000000003), (0.46744674467446745, 0.5140000000000003), (0.46726726726726725, 0.5150000000000003), (0.46630565583634176, 0.5160000000000003), (0.46626506024096387, 0.5170000000000003), (0.4650180940892642, 0.5180000000000003), (0.463768115942029, 0.5190000000000003), (0.4633998790078645, 0.5200000000000004), (0.46321525885558584, 0.5210000000000004), (0.4619581691421643, 0.5220000000000004), (0.46237864077669905, 0.5230000000000004), (0.45938545786431395, 0.5240000000000004), (0.45886654478976235, 0.5250000000000004), (0.4558509013137794, 0.5260000000000004), (0.4541003671970624, 0.5270000000000004), (0.4514742014742015, 0.5280000000000004), (0.45079950799507995, 0.5290000000000004), (0.4491682070240296, 0.5300000000000004), (0.4480098734958346, 0.5310000000000004), (0.44670991658943465, 0.5320000000000004), (0.4458874458874459, 0.5330000000000004), (0.4450634478489632, 0.5340000000000004), (0.44465116279069766, 0.5350000000000004), (0.4444444444444444, 0.5360000000000004), (0.4442373407890649, 0.5370000000000004), (0.4409841170974774, 0.5380000000000004), (0.44034978138663333, 0.5390000000000004), (0.4381846635367762, 0.5400000000000004), (0.43796992481203006, 0.5410000000000004), (0.43775478206334273, 0.5420000000000004), (0.43753923414940366, 0.5430000000000004), (0.43486469477658907, 0.5440000000000004), (0.4353312302839117, 0.5450000000000004), (0.43434343434343436, 0.5460000000000004), (0.4343977236800506, 0.5470000000000004), (0.43423137876386686, 0.5480000000000004), (0.4335131704220882, 0.5490000000000004), (0.43207126948775054, 0.5500000000000004), (0.43121019108280256, 0.5510000000000004), (0.4298469387755102, 0.5520000000000004), (0.42825183764781083, 0.5530000000000004), (0.42605068976580046, 0.5540000000000004), (0.4258188824662813, 0.5550000000000004), (0.425860405275008, 0.5560000000000004), (0.42447665056360706, 0.5570000000000004), (0.42410570415726717, 0.5580000000000004), (0.42400774443368827, 0.5590000000000004), (0.4241836404784998, 0.5600000000000004), (0.42241658568189183, 0.5610000000000004), (0.4198895027624309, 0.5620000000000004), (0.4176182707993475, 0.5630000000000004), (0.4172661870503597, 0.5640000000000004), (0.41702127659574467, 0.5650000000000004), (0.41521810429649064, 0.5660000000000004), (0.4140650673677292, 0.5670000000000004), (0.4131578947368421, 0.5680000000000004), (0.4119973632168754, 0.5690000000000004), (0.4117452985813263, 0.5700000000000004), (0.4097818902842036, 0.5710000000000004), (0.40860927152317883, 0.5720000000000004), (0.4090155783891283, 0.5730000000000004), (0.40730897009966777, 0.5740000000000004), (0.40652029274783763, 0.5750000000000004), (0.4059900166389351, 0.5760000000000004), (0.4046666666666667, 0.5770000000000004), (0.40240641711229946, 0.5780000000000004), (0.4012056262558607, 0.5790000000000004), (0.3987915407854985, 0.5800000000000004), (0.3971774193548387, 0.5810000000000004), (0.3952861952861953, 0.5820000000000004), (0.3940620782726046, 0.5830000000000004), (0.39270023656640757, 0.5840000000000004), (0.3906567366283006, 0.5850000000000004), (0.3898305084745763, 0.5860000000000004), (0.38722826086956524, 0.5870000000000004), (0.3851650221163661, 0.5880000000000004), (0.3845891578588476, 0.5890000000000004), (0.38524590163934425, 0.5900000000000004), (0.3850889192886457, 0.5910000000000004), (0.38424657534246576, 0.5920000000000004), (0.38324175824175827, 0.5930000000000004), (0.3822619456858027, 0.5940000000000004), (0.38167413021012747, 0.5950000000000004), (0.3794411866160745, 0.5960000000000004), (0.3775933609958506, 0.5970000000000004), (0.37534626038781166, 0.5980000000000004), (0.3749133749133749, 0.5990000000000004), (0.3739160596600763, 0.6000000000000004), (0.3714782608695652, 0.6010000000000004), (0.3712991988854058, 0.6020000000000004), (0.3705512909979065, 0.6030000000000004), (0.3689727463312369, 0.6040000000000004), (0.3682918274289723, 0.6050000000000004), (0.36771929824561406, 0.6060000000000004), (0.3674042852125044, 0.6070000000000004), (0.36523574947220266, 0.6080000000000004), (0.3642127509686509, 0.6090000000000004), (0.3622881355932203, 0.6100000000000004), (0.3622881355932203, 0.6110000000000004), (0.3602264685067233, 0.6120000000000004), (0.3574468085106383, 0.6130000000000004), (0.35757360766229157, 0.6140000000000004), (0.3565340909090909, 0.6150000000000004), (0.3541147132169576, 0.6160000000000004), (0.35306704707560627, 0.6170000000000004), (0.35214285714285715, 0.6180000000000004), (0.35050071530758226, 0.6190000000000004), (0.3508771929824561, 0.6200000000000004), (0.3508771929824561, 0.6210000000000004), (0.34816941852117733, 0.6220000000000004), (0.3472322070452912, 0.6230000000000004), (0.345821325648415, 0.6240000000000004), (0.34522522522522525, 0.6250000000000004), (0.3436823104693141, 0.6260000000000004), (0.3432080924855491, 0.6270000000000004), (0.3422575976845152, 0.6280000000000004), (0.3411807316189786, 0.6290000000000004), (0.3392662549945514, 0.6300000000000004), (0.3395129043984006, 0.6310000000000004), (0.336734693877551, 0.6320000000000005), (0.3346729996346365, 0.6330000000000005), (0.3323572474377745, 0.6340000000000005), (0.33186813186813185, 0.6350000000000005), (0.3301540719002201, 0.6360000000000005), (0.32978332721263315, 0.6370000000000005), (0.32941176470588235, 0.6380000000000005), (0.3264554163596168, 0.6390000000000005), (0.32669616519174044, 0.6400000000000005), (0.32705795496493173, 0.6410000000000005), (0.32482426933037367, 0.6420000000000005), (0.32420429311621024, 0.6430000000000005), (0.3224610822831727, 0.6440000000000005), (0.3208317861121426, 0.6450000000000005), (0.3195837978446674, 0.6460000000000005), (0.3185708969110532, 0.6470000000000005), (0.3162998881014547, 0.6480000000000005), (0.3156716417910448, 0.6490000000000005), (0.3157894736842105, 0.6500000000000005), (0.3145311916324244, 0.6510000000000005), (0.3145311916324244, 0.6520000000000005), (0.31350542461653574, 0.6530000000000005), (0.31247658298988384, 0.6540000000000005), (0.3099437148217636, 0.6550000000000005), (0.3089064261555806, 0.6560000000000005), (0.3078660143018442, 0.6570000000000005), (0.3082140165787491, 0.6580000000000005), (0.30780837419841567, 0.6590000000000005), (0.3066465256797583, 0.6600000000000005), (0.30507191521574567, 0.6610000000000005), (0.304133485020857, 0.6620000000000005), (0.3025465602432535, 0.6630000000000005), (0.3013698630136986, 0.6640000000000005), (0.30095238095238097, 0.6650000000000005), (0.3011818528402592, 0.6660000000000005), (0.29935089728904163, 0.6670000000000005), (0.2989296636085627, 0.6680000000000005), (0.2972041363462275, 0.6690000000000005), (0.29493087557603687, 0.6700000000000005), (0.29484218629715164, 0.6710000000000005), (0.29475308641975306, 0.6720000000000005), (0.29354963306295867, 0.6730000000000005), (0.29245647969052224, 0.6740000000000005), (0.29147286821705426, 0.6750000000000005), (0.28893203883495144, 0.6760000000000005), (0.2883793237465993, 0.6770000000000005), (0.2872713117944726, 0.6780000000000005), (0.2860483242400624, 0.6790000000000005), (0.28660679422100743, 0.6800000000000005), (0.28604923798358733, 0.6810000000000005), (0.28414872798434443, 0.6820000000000005), (0.28414872798434443, 0.6830000000000005), (0.2829153605015674, 0.6840000000000005), (0.2822422579380635, 0.6850000000000005), (0.281900274833137, 0.6860000000000005), (0.2804253643166601, 0.6870000000000005), (0.27940015785319655, 0.6880000000000005), (0.27848101265822783, 0.6890000000000005), (0.27812995245641836, 0.6900000000000005), (0.2755061532354109, 0.6910000000000005), (0.2733067729083665, 0.6920000000000005), (0.27225548902195607, 0.6930000000000005), (0.2683219863836604, 0.6940000000000005), (0.26575672420714574, 0.6950000000000005), (0.26516673362796306, 0.6960000000000005), (0.2644694533762058, 0.6970000000000005), (0.26339105920257755, 0.6980000000000005), (0.2616067823980622, 0.6990000000000005), (0.2580906148867314, 0.7000000000000005), (0.25759416767922233, 0.7010000000000005), (0.2563894523326572, 0.7020000000000005), (0.25457503050020336, 0.7030000000000005), (0.253257328990228, 0.7040000000000005), (0.25122349102773245, 0.7050000000000005), (0.24989791751735402, 0.7060000000000005), (0.24887433483422022, 0.7070000000000005), (0.24754098360655738, 0.7080000000000005), (0.24476386036960984, 0.7090000000000005), (0.2448644207066557, 0.7100000000000005), (0.24269847799259564, 0.7110000000000005), (0.2420749279538905, 0.7120000000000005), (0.24217462932454695, 0.7130000000000005), (0.24082474226804124, 0.7140000000000005), (0.23821339950372208, 0.7150000000000005), (0.23748448489863466, 0.7160000000000005), (0.2367549668874172, 0.7170000000000005), (0.2367549668874172, 0.7180000000000005), (0.2353916286779942, 0.7190000000000005), (0.23402489626556017, 0.7200000000000005), (0.23402489626556017, 0.7210000000000005), (0.23333333333333334, 0.7220000000000005), (0.23195661243220692, 0.7230000000000005), (0.2297410192147034, 0.7240000000000005), (0.22826086956521738, 0.7250000000000005), (0.2273489932885906, 0.7260000000000005), (0.22530474989491384, 0.7270000000000005), (0.2248421052631579, 0.7280000000000005), (0.22353437368199072, 0.7290000000000005), (0.22241014799154335, 0.7300000000000005), (0.2195845697329377, 0.7310000000000005), (0.21617021276595744, 0.7320000000000005), (0.2143467122117848, 0.7330000000000005), (0.21358393848782573, 0.7340000000000005), (0.21003000428632662, 0.7350000000000005), (0.20926243567753003, 0.7360000000000005), (0.2084942084942085, 0.7370000000000005), (0.20395869191049915, 0.7380000000000005), (0.2040464916056823, 0.7390000000000005), (0.2025862068965517, 0.7400000000000005), (0.20198532585239534, 0.7410000000000005), (0.19896193771626297, 0.7420000000000005), (0.19939315127871696, 0.7430000000000005), (0.19556714471968709, 0.7440000000000005), (0.19321148825065274, 0.7450000000000006), (0.19172113289760348, 0.7460000000000006), (0.19014391626689925, 0.7470000000000006), (0.18714473108876256, 0.7480000000000006), (0.1864332603938731, 0.7490000000000006), (0.1850065760631302, 0.7500000000000006), (0.18357487922705315, 0.7510000000000006), (0.18213814342278928, 0.7520000000000006), (0.1814178775869661, 0.7530000000000006), (0.18069634200088144, 0.7540000000000006), (0.18069634200088144, 0.7550000000000006), (0.17675651789659744, 0.7560000000000006), (0.1760283060592658, 0.7570000000000006), (0.1752212389380531, 0.7580000000000006), (0.17360496014171833, 0.7590000000000006), (0.17287234042553193, 0.7600000000000006), (0.1705150976909414, 0.7610000000000006), (0.16814946619217083, 0.7620000000000006), (0.1665924276169265, 0.7630000000000006), (0.1665924276169265, 0.7640000000000006), (0.1657754010695187, 0.7650000000000006), (0.1657754010695187, 0.7660000000000006), (0.16599732262382866, 0.7670000000000006), (0.16517857142857142, 0.7680000000000006), (0.16450603486812695, 0.7690000000000006), (0.16315553563424473, 0.7700000000000006), (0.16322869955156952, 0.7710000000000006), (0.16269662921348316, 0.7720000000000006), (0.16194331983805668, 0.7730000000000006), (0.16118865375956776, 0.7740000000000006), (0.1580135440180587, 0.7750000000000006), (0.15565610859728507, 0.7760000000000006), (0.15482118605703937, 0.7770000000000006), (0.1542649727767695, 0.7780000000000006), (0.15433499773036768, 0.7790000000000006), (0.15279672578444747, 0.7800000000000006), (0.1520254893035958, 0.7810000000000006), (0.1520254893035958, 0.7820000000000006), (0.15209471766848817, 0.7830000000000006), (0.14885844748858448, 0.7840000000000006), (0.1480804387568556, 0.7850000000000006), (0.14560439560439561, 0.7860000000000006), (0.1439706556625401, 0.7870000000000006), (0.1425287356321839, 0.7880000000000006), (0.1408839779005525, 0.7890000000000006), (0.1392346703550023, 0.7900000000000006), (0.13764434180138568, 0.7910000000000006), (0.13333333333333333, 0.7920000000000006), (0.13259156235512284, 0.7930000000000006), (0.12912215513237343, 0.7940000000000006), (0.12738261273826126, 0.7950000000000006), (0.1275011633317822, 0.7960000000000006), (0.12581547064305684, 0.7970000000000006), (0.1241250583294447, 0.7980000000000006), (0.1241250583294447, 0.7990000000000006), (0.12424100887435778, 0.8000000000000006), (0.12424100887435778, 0.8010000000000006), (0.1225444340505145, 0.8020000000000006), (0.1225444340505145, 0.8030000000000006), (0.11990632318501171, 0.8040000000000006), (0.11825434068512436, 0.8050000000000006), (0.1156558533145275, 0.8060000000000006), (0.11388235294117648, 0.8070000000000006), (0.11210551106924165, 0.8080000000000006), (0.11210551106924165, 0.8090000000000006), (0.11215834118755891, 0.8100000000000006), (0.11132075471698114, 0.8110000000000006), (0.11042944785276074, 0.8120000000000006), (0.11048158640226628, 0.8130000000000006), (0.10879848628192999, 0.8140000000000006), (0.10710900473933649, 0.8150000000000006), (0.10441385856668249, 0.8160000000000006), (0.10090433127082342, 0.8170000000000006), (0.09914204003813155, 0.8180000000000006), (0.09918931807343824, 0.8190000000000006), (0.0982824427480916, 0.8200000000000006), (0.09746774964166269, 0.8210000000000006), (0.09395973154362416, 0.8220000000000006), (0.08846153846153847, 0.8230000000000006), (0.08674698795180723, 0.8240000000000006), (0.085824493731919, 0.8250000000000006), (0.08594881699661999, 0.8260000000000006), (0.08413926499032882, 0.8270000000000006), (0.08321238509917755, 0.8280000000000006), (0.08325266214908035, 0.8290000000000006), (0.08337372758119244, 0.8300000000000006), (0.08341416100872939, 0.8310000000000006), (0.0797277588721439, 0.8320000000000006), (0.07797270955165692, 0.8330000000000006), (0.07327796775769418, 0.8340000000000006), (0.07233626588465299, 0.8350000000000006), (0.07139364303178485, 0.8360000000000006), (0.07149853085210578, 0.8370000000000006), (0.07055365017148457, 0.8380000000000006), (0.0696078431372549, 0.8390000000000006), (0.06869479882237488, 0.8400000000000006), (0.06869479882237488, 0.8410000000000006), (0.06869479882237488, 0.8420000000000006), (0.06774668630338733, 0.8430000000000006), (0.06777996070726916, 0.8440000000000006), (0.06683046683046683, 0.8450000000000006), (0.06683046683046683, 0.8460000000000006), (0.06683046683046683, 0.8470000000000006), (0.06591244466305952, 0.8480000000000006), (0.06496062992125984, 0.8490000000000006), (0.06496062992125984, 0.8500000000000006), (0.06407097092163627, 0.8510000000000006), (0.0641025641025641, 0.8520000000000006), (0.06413418845584608, 0.8530000000000006), (0.06413418845584608, 0.8540000000000006), (0.06419753086419754, 0.8550000000000006), (0.06228373702422145, 0.8560000000000006), (0.06231454005934718, 0.8570000000000007), (0.061355764473033154, 0.8580000000000007), (0.061355764473033154, 0.8590000000000007), (0.061355764473033154, 0.8600000000000007), (0.061355764473033154, 0.8610000000000007), (0.060515873015873016, 0.8620000000000007), (0.05961251862891207, 0.8630000000000007), (0.056716417910447764, 0.8640000000000007), (0.056716417910447764, 0.8650000000000007), (0.05674464907914385, 0.8660000000000007), (0.05674464907914385, 0.8670000000000007), (0.055776892430278883, 0.8680000000000007), (0.055776892430278883, 0.8690000000000007), (0.055776892430278883, 0.8700000000000007), (0.053865336658354114, 0.8710000000000007), (0.053865336658354114, 0.8720000000000007), (0.05389221556886228, 0.8730000000000007), (0.05292061907139291, 0.8740000000000007), (0.05292061907139291, 0.8750000000000007), (0.05292061907139291, 0.8760000000000007), (0.050974512743628186, 0.8770000000000007), (0.050974512743628186, 0.8780000000000007), (0.05, 0.8790000000000007), (0.05, 0.8800000000000007), (0.05, 0.8810000000000007), (0.05, 0.8820000000000007), (0.05002501250625312, 0.8830000000000007), (0.05002501250625312, 0.8840000000000007), (0.05012531328320802, 0.8850000000000007), (0.05015045135406219, 0.8860000000000007), (0.04917210235825389, 0.8870000000000007), (0.048216976393771975, 0.8880000000000007), (0.048216976393771975, 0.8890000000000007), (0.0473313192346425, 0.8900000000000007), (0.04634760705289673, 0.8910000000000007), (0.04634760705289673, 0.8920000000000007), (0.0453857791225416, 0.8930000000000007), (0.0453857791225416, 0.8940000000000007), (0.0453857791225416, 0.8950000000000007), (0.0453857791225416, 0.8960000000000007), (0.0453857791225416, 0.8970000000000007), (0.0453857791225416, 0.8980000000000007), (0.0453857791225416, 0.8990000000000007), (0.045408678102926335, 0.9000000000000007), (0.043434343434343436, 0.9010000000000007), (0.04244567963617989, 0.9020000000000007), (0.041456016177957536, 0.9030000000000007), (0.041456016177957536, 0.9040000000000007), (0.041456016177957536, 0.9050000000000007), (0.041456016177957536, 0.9060000000000007), (0.04046535154274153, 0.9070000000000007), (0.04046535154274153, 0.9080000000000007), (0.04046535154274153, 0.9090000000000007), (0.04046535154274153, 0.9100000000000007), (0.04046535154274153, 0.9110000000000007), (0.04048582995951417, 0.9120000000000007), (0.04048582995951417, 0.9130000000000007), (0.03949367088607595, 0.9140000000000007), (0.03949367088607595, 0.9150000000000007), (0.03850050658561297, 0.9160000000000007), (0.03750633552965028, 0.9170000000000007), (0.036511156186612576, 0.9180000000000007), (0.036511156186612576, 0.9190000000000007), (0.0335195530726257, 0.9200000000000007), (0.0335195530726257, 0.9210000000000007), (0.0335195530726257, 0.9220000000000007), (0.032520325203252036, 0.9230000000000007), (0.032520325203252036, 0.9240000000000007), (0.032520325203252036, 0.9250000000000007), (0.032520325203252036, 0.9260000000000007), (0.032520325203252036, 0.9270000000000007), (0.0315200813421454, 0.9280000000000007), (0.0315200813421454, 0.9290000000000007), (0.0315200813421454, 0.9300000000000007), (0.0315200813421454, 0.9310000000000007), (0.030518819938962362, 0.9320000000000007), (0.029531568228105907, 0.9330000000000007), (0.029531568228105907, 0.9340000000000007), (0.028527763627101375, 0.9350000000000007), (0.02854230377166157, 0.9360000000000007), (0.027551020408163266, 0.9370000000000007), (0.026544155181214904, 0.9380000000000007), (0.026544155181214904, 0.9390000000000007), (0.026544155181214904, 0.9400000000000007), (0.026557711950970377, 0.9410000000000007), (0.026571282575370465, 0.9420000000000007), (0.026571282575370465, 0.9430000000000007), (0.026571282575370465, 0.9440000000000007), (0.02354145342886387, 0.9450000000000007), (0.023553507424475168, 0.9460000000000007), (0.023553507424475168, 0.9470000000000007), (0.023553507424475168, 0.9480000000000007), (0.023553507424475168, 0.9490000000000007), (0.020512820512820513, 0.9500000000000007), (0.020512820512820513, 0.9510000000000007), (0.019497178040020522, 0.9520000000000007), (0.019497178040020522, 0.9530000000000007), (0.018480492813141684, 0.9540000000000007), (0.018480492813141684, 0.9550000000000007), (0.01746276322547509, 0.9560000000000007), (0.01746276322547509, 0.9570000000000007), (0.01746276322547509, 0.9580000000000007), (0.01746276322547509, 0.9590000000000007), (0.01746276322547509, 0.9600000000000007), (0.01644398766700925, 0.9610000000000007), (0.013388259526261586, 0.9620000000000007), (0.013388259526261586, 0.9630000000000007), (0.012364760432766615, 0.9640000000000007), (0.012364760432766615, 0.9650000000000007), (0.012364760432766615, 0.9660000000000007), (0.012364760432766615, 0.9670000000000007), (0.01134020618556701, 0.9680000000000007), (0.01134020618556701, 0.9690000000000007), (0.01134020618556701, 0.9700000000000008), (0.01134020618556701, 0.9710000000000008), (0.01134020618556701, 0.9720000000000008), (0.01134020618556701, 0.9730000000000008), (0.01134020618556701, 0.9740000000000008), (0.01134020618556701, 0.9750000000000008), (0.010314595152140279, 0.9760000000000008), (0.010314595152140279, 0.9770000000000008), (0.008260196179659268, 0.9780000000000008), (0.008260196179659268, 0.9790000000000008), (0.007231404958677686, 0.9800000000000008), (0.007231404958677686, 0.9810000000000008), (0.007231404958677686, 0.9820000000000008), (0.007231404958677686, 0.9830000000000008), (0.007231404958677686, 0.9840000000000008), (0.007238883143743537, 0.9850000000000008), (0.007238883143743537, 0.9860000000000008), (0.007238883143743537, 0.9870000000000008), (0.007238883143743537, 0.9880000000000008), (0.007238883143743537, 0.9890000000000008), (0.007238883143743537, 0.9900000000000008), (0.007238883143743537, 0.9910000000000008), (0.007238883143743537, 0.9920000000000008), (0.006207966890843249, 0.9930000000000008), (0.006207966890843249, 0.9940000000000008), (0.006207966890843249, 0.9950000000000008), (0.006207966890843249, 0.9960000000000008), (0.006207966890843249, 0.9970000000000008), (0.006211180124223602, 0.9980000000000008), (0.0031120331950207467, 0.9990000000000008)]\n"
     ]
    }
   ],
   "source": [
    "print( listLenientJudge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.358148893360161\n"
     ]
    }
   ],
   "source": [
    "print(max([listStringentJudge1][0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
